{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkNet: Network for Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abhishek Chaurasia, Eugenio Culurciello, Jun 2017, https://arxiv.org/abs/1707.03718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinkNet architecture is inspired by auto-encoders: each encoder (decoder) performs downsampling (upsampling) the feature maps by a factor of 2. At the same time the number of channels increases (decreases) except the outputs of the first encoder-decoder blocks. The main novelty of LinkNet as a segmenation network is a usage of skip connections between encoders and decoders. This\n",
    "approach enables to save spatial information that contains in input image and helps to train neural networks. Each convolutional layer is followed by batch-normalization and ReLU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./pic/01.PNG' width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic/02.PNG' width=\"1000\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use LinkNet to segmenation of $128 \\times 128$ images with MNIST $28 \\times 28$ at random place (uniformly sampled) with noise generated on the base of MNIST fragments. Each fragment is randomly cutted from random image from the same batch and is rotated by an angle $ \\sim U(0,360^{\\circ})$. Coordinates of top-left corner are sampled from uniform $U(0, 128-s)$ or normal $N\\left(\\frac{128-s}{2}, \\left(\\frac{128-s}{4}\\right)^2\\right)$ distribution where $s$ is equal to width (height) of rotated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv1d_transpose' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-92f7274adb5b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlinknet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinkNetModel\u001b[0m                                  \u001b[1;31m# TFModel subclass with LinkNet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNoisedMnist\u001b[0m                                          \u001b[1;31m# Batch subclass with loading and noise actions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplot_functions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_noised_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_examples_highlighted\u001b[0m \u001b[1;31m# plot functions to demonstrate result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\task_02\\linknet.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\" LinkNet as TFModel \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msegmentation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSegmentationModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\models\\tf\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\" Contains tensorflow models and functions \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtf_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTFModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\models\\tf\\tf_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBaseModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdice\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\models\\tf\\losses\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\models\\tf\\layers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1d_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv2d_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv3d_block\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\models\\tf\\layers\\conv.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m'conv'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3d\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;34m'batch-norm'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_normalization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[1;34m'transposed-conv'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mconv1d_transpose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d_transpose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3d_transpose\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;34m'max-pooling'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pooling1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pooling2d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pooling3d\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;34m'dropout'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'conv1d_transpose' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from dataset import Pipeline, DatasetIndex, Dataset, B, C, F, V\n",
    "\n",
    "from linknet import LinkNetModel                                  # TFModel subclass with LinkNet\n",
    "from nmnist import NoisedMnist                                          # Batch subclass with loading and noise actions\n",
    "from plot_functions import plot_noised_image, plot_examples_highlighted # plot functions to demonstrate result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix constants to generate noised images and train LinkNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64     # image size\n",
    "MNIST_SIZE = 1000   # MNIST database size\n",
    "BATCH_SIZE = 256     # batch size for NN training\n",
    "MAX_ITER = 5       # number of iterations for NN training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define noise parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level = 1           # the highest level of noise; [0, 1]\n",
    "n_fragments = 60    # number of noise fragments per image  \n",
    "size = 8            # size of noise fragment; 1, ..., 27\n",
    "distr = 'normal'    # distribution of fragments of image; 'uniform' or 'normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DatasetIndex and Dataset to use pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = DatasetIndex(np.arange(MNIST_SIZE))          # index for images\n",
    "mnistset = Dataset(ind, batch_class=NoisedMnist)   # Dataset with transform actions in NoisedMnist class\n",
    "mnistset.cv_split([0.9, 0.1])                      # divide it into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð¡reate Pipeline template for image loading and transformation. The first parameter of create_noise is the type of noise: 'mnist_noise' - MNIST-based noise, 'random_noise' - uniform random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_template = (Pipeline()\n",
    "                 .load_images()                    # load MNIST images from file\n",
    "                 .random_location(IMAGE_SIZE)      # put MNIST at random location\n",
    "                 .create_mask()                    # create mask for MNIST image location\n",
    "                 .create_noise('mnist_noise',\n",
    "                            level,\n",
    "                            n_fragments, \n",
    "                            size, \n",
    "                            distr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot example of noised images (train images are greyscale but we highlight true digit in yellow to plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xc7ecba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = []\n",
    "noise = []\n",
    "(load_template << mnistset.train).get_images(images).get_noise(noise).next_batch(10, shuffle=True)\n",
    "plot_noised_image(images[0][0], noise[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feed_dict's for TFModel. \n",
    "* '<b>input_image</b>' - name of input placeholdes described in TFModel\n",
    "* '<b>images</b>' - name of attribute in NoisedMnist class\n",
    "* '<b>targets</b>' - name of target placeholdes described in TFModel\n",
    "* '<b>masks</b>' - name of attribute in NoisedMnist class\n",
    "* '<b>bn_mode</b>' - name of placeholdes for batch normalization training parameter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feed_dict = {'input_image': B('images'),\n",
    "                   'targets': B('masks')}        \n",
    "\n",
    "test_feed_dict = {'input_image': B('images'),\n",
    "                  'targets': B('masks')}\n",
    "\n",
    "model_config = {'loss': 'softmax_cross_entropy',\n",
    "                'optimizer': 'Adam',\n",
    "                'n_classes': 2,\n",
    "                'dim': 2,\n",
    "                'images_shape': (IMAGE_SIZE, IMAGE_SIZE)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"LinkNet/4th_encoder/encoder_add_2:0\", shape=(?, 1, 1, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "ppl_train = ((load_template << mnistset.train)\n",
    "            .add_noise()\n",
    "            .init_variable('train_loss_history', init_on_each_run=list)\n",
    "            .init_model('static',                                          # model mode\n",
    "                        LinkNetModel,                                      # TFModel subclass with LinkNet\n",
    "                        'linknet',                                         # model name\n",
    "                        config=model_config)\n",
    "            .train_model('linknet',                                        # model name\n",
    "                         fetches='loss',                                   # tensors to get value \n",
    "                         feed_dict=train_feed_dict,                        \n",
    "                         append_to=V('train_loss_history')))                  # name of pipeline variable to save loss value\n",
    "\n",
    "ppl_test = ((load_template << mnistset.test)\n",
    "            .add_noise()\n",
    "            .import_model('linknet', ppl_train)\n",
    "            .init_variable('test_loss_history', init_on_each_run=list)\n",
    "            .predict_model('linknet', \n",
    "                           fetches='loss',\n",
    "                           feed_dict=test_feed_dict,\n",
    "                           append_to=V('test_loss_history')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LinkNet on noised data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   1: train 1.577 test 1.386\n",
      "Iter   2: train 1.492 test 1.385\n",
      "Iter   3: train 1.431 test 1.386\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e21c129d3568>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_ITER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mppl_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m                              \u001b[1;31m# training step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mppl_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m                                      \u001b[1;31m# compute test loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36mnext_batch\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1067\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m             \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m             \u001b[0m_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36mgen_batch\u001b[1;34m(self, batch_size, shuffle, n_epochs, drop_last, prefetch, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1043\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m                     \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mSkipBatchException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec\u001b[1;34m(self, batch, new_loop)\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m         \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_all_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m         \u001b[0mbatch_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch_res\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec_all_actions\u001b[1;34m(self, batch, action_list)\u001b[0m\n\u001b[0;32m    543\u001b[0m                 \u001b[0m_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'#dont_run'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTRAIN_MODEL_ID\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPREDICT_MODEL_ID\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_predict_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec_train_model\u001b[1;34m(self, batch, action)\u001b[0m\n\u001b[0;32m    802\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_model_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_model_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 804\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    805\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'append_to'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_model_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'save_to'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\models\\tf\\tf_model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m                 \u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fill_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_feed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training of the model\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    ppl_train.next_batch(BATCH_SIZE, n_epochs=None)                              # training step\n",
    "    ppl_test.next_batch(100, n_epochs=None)                                      # compute test loss\n",
    "    \n",
    "    train_loss = ppl_train.get_variable('train_loss_history')[-1]                # get current iteration train loss\n",
    "    test_loss = ppl_test.get_variable('test_loss_history')[-1]                   # get current iteration test loss\n",
    "    \n",
    "    if (i+1) % 1 == 0:\n",
    "        print(\"Iter {:3d}: train {:05.3f} test {:05.3f}\".format(i+1, train_loss, test_loss))\n",
    "        \n",
    "stop = time()\n",
    "\n",
    "print(\"Train time: {:05.3f} min\".format((stop-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot train and test loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(ppl_train.get_variable('train_loss_history'), label='Train loss')\n",
    "plt.plot(ppl_test.get_variable('test_loss_history'), label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline to get some images from test dataset and corresponding masks, noise and mask predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "noise = []\n",
    "\n",
    "ppl_plot = ((load_template << mnistset.test)                       # load data from file\n",
    "             .get_images(images)                                   # images without noise\n",
    "             .get_masks(masks)                                     # get masks\n",
    "             .get_noise(noise)                                     # get noise\n",
    "             .add_noise()                                          # add noise to images\n",
    "             .import_model('linknet', ppl_train)\n",
    "             .init_variable('predictions', init_on_each_run=list)\n",
    "             .predict_model('linknet',                                      \n",
    "                           fetches='predicted_prob',\n",
    "                           feed_dict=test_feed_dict,\n",
    "                           append_to=V('predictions')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for 10 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppl_plot.next_batch(10, n_epochs=None)\n",
    "predictions = ppl_plot.get_variable('predictions')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot images with highlighted digit, mask for $28 \\times 28$ image, binary mask prediction and probability prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_examples_highlighted(images, noise, masks, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
