{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkNet: Network for Semantic Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abhishek Chaurasia, Eugenio Culurciello, Jun 2017, https://arxiv.org/abs/1707.03718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LinkNet architecture is inspired by auto-encoders: each encoder (decoder) performs downsampling (upsampling) the feature maps by a factor of 2. At the same time the number of channels increases (decreases) except the outputs of the first encoder-decoder blocks. The main novelty of LinkNet as a segmenation network is a usage of skip connections between encoders and decoders. This\n",
    "approach enables to save spatial information that contains in input image and helps to train neural networks. Each convolutional layer is followed by batch-normalization and ReLU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./pic/01.PNG' width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pic/02.PNG' width=\"1000\" height=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use LinkNet to segmenation of $128 \\times 128$ images with MNIST $28 \\times 28$ at random place (uniformly sampled) with noise generated on the base of MNIST fragments. Each fragment is randomly cutted from random image from the same batch and is rotated by an angle $ \\sim U(0,360^{\\circ})$. Coordinates of top-left corner are sampled from uniform $U(0, 128-s)$ or normal $N\\left(\\frac{128-s}{2}, \\left(\\frac{128-s}{4}\\right)^2\\right)$ distribution where $s$ is equal to width (height) of rotated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../base_networks/segmentation/\")\n",
    "sys.path.append(\"../base_networks/classification/\")\n",
    "\n",
    "from dataset import Pipeline, DatasetIndex, Dataset, B, C, F, V\n",
    "\n",
    "from fcn import FCNModel\n",
    "from unet import UNetModel\n",
    "from linknet import LinkNetModel                                  # TFModel subclass with LinkNet\n",
    "from nmnist import NoisedMnist                                          # Batch subclass with loading and noise actions\n",
    "from plot_functions import plot_noised_image, plot_examples_highlighted # plot functions to demonstrate result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix constants to generate noised images and train LinkNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64     # image size\n",
    "MNIST_SIZE = 65000   # MNIST database size\n",
    "BATCH_SIZE = 128     # batch size for NN training\n",
    "MAX_ITER = 100       # number of iterations for NN training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define noise parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level = 1           # the highest level of noise; [0, 1]\n",
    "n_fragments = 30    # number of noise fragments per image  \n",
    "size = 8            # size of noise fragment; 1, ..., 27\n",
    "distr = 'normal'    # distribution of fragments of image; 'uniform' or 'normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DatasetIndex and Dataset to use pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = DatasetIndex(np.arange(MNIST_SIZE))          # index for images\n",
    "mnistset = Dataset(ind, batch_class=NoisedMnist)   # Dataset with transform actions in NoisedMnist class\n",
    "mnistset.cv_split([0.9, 0.1])                      # divide it into train and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð¡reate Pipeline template for image loading and transformation. The first parameter of create_noise is the type of noise: 'mnist_noise' - MNIST-based noise, 'random_noise' - uniform random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_template = (Pipeline()\n",
    "                 .load_images()                    # load MNIST images from file\n",
    "                 .random_location(IMAGE_SIZE)      # put MNIST at random location\n",
    "                 .create_mask()                    # create mask for MNIST image location\n",
    "                 .create_noise('mnist_noise',\n",
    "                            level,\n",
    "                            n_fragments, \n",
    "                            size, \n",
    "                            distr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot example of noised images (train images are greyscale but we highlight true digit in yellow to plot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHlLhi3hIhS/iIRW+iIf+HyzQ5C11BAZ0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xdb8e4a8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = []\n",
    "noise = []\n",
    "(load_template << mnistset.train).get_images(images).get_noise(noise).next_batch(10, shuffle=True)\n",
    "plot_noised_image(images[0][0], noise[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create config for placeholders of the model. Key in dict is name of the created placeholder.\n",
    "* '<b>shape</b>' - shape of the input of model\n",
    "* '<b>type</b>' - tf.dtype of input\n",
    "* '<b>data_format</b>' - one of channels_last (default) or channels_first\n",
    "* '<b>name</b>' - name of the placeholder after reshaping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeholders_config = {\n",
    "                       'images': {'shape': (IMAGE_SIZE, IMAGE_SIZE, 1),\n",
    "                                 'type': 'float32',\n",
    "                                 'data_format': 'channels_last',\n",
    "                                 'name': 'reshaped_images'},\n",
    "                \n",
    "                       'masks': {'shape': (IMAGE_SIZE, IMAGE_SIZE, 2),\n",
    "                                 'type': 'int32',\n",
    "                                 'data_format': 'channels_last',\n",
    "                                 'name': 'targets'}\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model_config.\n",
    "* '<b>placeholders</b>' - dict of placeholders configs\n",
    "* '<b>n_classes</b>' - number of output classes\n",
    "* '<b>b_norm</b>' - enable batch normalization\n",
    "* '<b>loss</b>' - loss function\n",
    "* '<b>optimizer</b>' - loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_config = {'inputs': placeholders_config,\n",
    "                'batch_norm': False,\n",
    "                'loss': 'softmax_cross_entropy',\n",
    "                'optimizer': 'Adam'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feed dicts. The key is name of the tensor in tf graph, value is batch component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feed_dict = {'images': B('images'),\n",
    "                   'masks': B('masks')}        \n",
    "\n",
    "test_feed_dict = {'images': B('images'),\n",
    "                  'masks': B('masks')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train and test pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_train = ((load_template << mnistset.train)\n",
    "            .add_noise()\n",
    "            .init_variable('train_loss_history', init_on_each_run=list)\n",
    "            .init_model('static',                                          # model mode\n",
    "                         FCNModel,                                      # TFModel subclass with LinkNet\n",
    "                        'linknet',                                         # model name\n",
    "                        config=model_config)\n",
    "            .train_model('linknet',                                        # model name\n",
    "                         fetches='loss',                                   # tensors to get value \n",
    "                         feed_dict=train_feed_dict,                        \n",
    "                         save_to=V('train_loss_history'), mode='a'))                  # name of pipeline variable to save loss value\n",
    "\n",
    "ppl_test = ((load_template << mnistset.test)\n",
    "            .add_noise()\n",
    "            .import_model('linknet', ppl_train)\n",
    "            .init_variable('test_loss_history', init_on_each_run=list)\n",
    "            .predict_model('linknet', \n",
    "                           fetches='loss',\n",
    "                           feed_dict=test_feed_dict,\n",
    "                           save_to=V('test_loss_history'), mode='a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train LinkNet on noised data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   1: train 1.387 test 1.385\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b1455d9692c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMAX_ITER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mppl_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m                              \u001b[1;31m# training step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mppl_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m                                      \u001b[1;31m# compute test loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36mnext_batch\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1088\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1089\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1090\u001b[1;33m             \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1091\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m             \u001b[0m_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36mgen_batch\u001b[1;34m(self, batch_size, shuffle, n_epochs, drop_last, prefetch, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1064\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1066\u001b[1;33m                     \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1067\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mSkipBatchException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec\u001b[1;34m(self, batch, new_loop)\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_all_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    568\u001b[0m         \u001b[0mbatch_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch_res\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec_all_actions\u001b[1;34m(self, batch, action_list)\u001b[0m\n\u001b[0;32m    534\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_import_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTRAIN_MODEL_ID\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 536\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    537\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mPREDICT_MODEL_ID\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_predict_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec_train_model\u001b[1;34m(self, batch, action)\u001b[0m\n\u001b[0;32m    831\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_model_by_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_model_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'save_to'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mode'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Python projects\\az_training\\dataset\\dataset\\models\\tf\\tf_model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m                 \u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fill_fetches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m             \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fetches\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_feed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training of the model\n",
    "\n",
    "start = time()\n",
    "\n",
    "for i in range(MAX_ITER):\n",
    "    ppl_train.next_batch(BATCH_SIZE, n_epochs=None, shuffle=True)                              # training step\n",
    "    ppl_test.next_batch(100, n_epochs=None, shuffle=True)                                      # compute test loss\n",
    "    \n",
    "    train_loss = ppl_train.get_variable('train_loss_history')[-1]                # get current iteration train loss\n",
    "    test_loss = ppl_test.get_variable('test_loss_history')[-1]                   # get current iteration test loss\n",
    "    \n",
    "    if (i+1) % 1 == 0:\n",
    "        print(\"Iter {:3d}: train {:05.3f} test {:05.3f}\".format(i+1, train_loss, test_loss))\n",
    "        \n",
    "stop = time()\n",
    "\n",
    "print(\"Train time: {:05.3f} min\".format((stop-start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot train and test loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(ppl_train.get_variable('train_loss_history'), label='Train loss')\n",
    "plt.plot(ppl_test.get_variable('test_loss_history'), label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create pipeline to get some images from test dataset and corresponding masks, noise and mask predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "noise = []\n",
    "\n",
    "ppl_plot = ((load_template << mnistset.test)                       # load data from file\n",
    "             .get_images(images)                                   # images without noise\n",
    "             .get_masks(masks)                                     # get masks\n",
    "             .get_noise(noise)                                     # get noise\n",
    "             .add_noise()                                          # add noise to images\n",
    "             .import_model('linknet', ppl_train)\n",
    "             .init_variable('predictions', init_on_each_run=list)\n",
    "             .predict_model('linknet',                                      \n",
    "                           fetches='predicted_prob',\n",
    "                           feed_dict=test_feed_dict,\n",
    "                           save_to=V('predictions'),\n",
    "                           mode='a'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for 10 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppl_plot.next_batch(10, n_epochs=None)\n",
    "predictions = ppl_plot.get_variable('predictions')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot images with highlighted digit, mask for $28 \\times 28$ image, binary mask prediction and probability prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_examples_highlighted(images, noise, masks, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
