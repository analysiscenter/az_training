{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use LinkNet, UNet, FCN32 and FCN8 (realized as TFModel) to segmenation of $64 \\times 64$ images with MNIST $28 \\times 28$ at random place (uniformly sampled) with noise generated on the base of MNIST fragments. Each fragment is randomly cutted from random image from the same batch and is rotated by an angle $ \\sim U(0,360^{\\circ})$. Coordinates of top-left corner are sampled from uniform $U(0, 64-s)$ or normal $N\\left(\\frac{64-s}{2}, \\left(\\frac{64-s}{4}\\right)^2\\right)$ distribution where $s$ is equal to width (height) of rotated image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dataset import Pipeline, DatasetIndex, Dataset, B, C, F, V\n",
    "\n",
    "from dataset.opensets import MNIST\n",
    "from dataset.dataset.models.tf import UNet, LinkNet, FCN32, FCN8\n",
    "from noised_mnist import NoisedMnist                                          # Batch subclass with loading and noise actions\n",
    "from plot_functions import plot_noised_image, plot_examples_highlighted # plot functions to demonstrate result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix constants to generate noised images and train LinkNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64     # image size\n",
    "MNIST_SIZE = 65000  # MNIST database size\n",
    "BATCH_SIZE = 32     # batch size for NN training\n",
    "MAX_ITER = 500      # number of iterations for NN training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define noise parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level = 1           # the highest level of noise; [0, 1]\n",
    "n_fragments = 80    # number of noise fragments per image  \n",
    "size = 4            # size of noise fragment; 1, ..., 27\n",
    "distr = 'uniform'   # distribution of fragments of image; 'uniform' or 'normal'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DatasetIndex and Dataset to use pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ExtractingExtractingC:\\Users\\kozhevin\\AppData\\Local\\Temp\\train-labels-idx1-ubyte.gz  Extracting\n",
      "C:\\Users\\kozhevin\\AppData\\Local\\Temp\\train-images-idx3-ubyte.gzC:\\Users\\kozhevin\\AppData\\Local\\Temp\\t10k-labels-idx1-ubyte.gz C:\\Users\\kozhevin\\AppData\\Local\\Temp\\t10k-images-idx3-ubyte.gz\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mnistset = MNIST(batch_class=NoisedMnist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ð¡reate Pipeline template for image loading and transformation. The first parameter of create_noise is the type of noise: 'mnist_noise' - MNIST-based noise, 'random_noise' - uniform random noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_template = (Pipeline()\n",
    "                 .random_location(IMAGE_SIZE)      # put MNIST at random location\n",
    "                 .create_mask()                    # create mask for MNIST image location\n",
    "                 .create_noise('mnist_noise',\n",
    "                            level,\n",
    "                            n_fragments, \n",
    "                            size, \n",
    "                            distr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create config for placeholders of the model. Key in dict is name of the created placeholder.\n",
    "* '<b>shape</b>' - shape of the input of model\n",
    "* '<b>type</b>' - tf.dtype of input\n",
    "* '<b>data_format</b>' - one of channels_last (default) or channels_first\n",
    "* '<b>name</b>' - name of the placeholder after reshaping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeholders_config = {\n",
    "                       'images': {'shape': (IMAGE_SIZE, IMAGE_SIZE, 1),\n",
    "                                 'type': 'float32',\n",
    "                                 'data_format': 'channels_last',\n",
    "                                 'name': 'reshaped_images'},\n",
    "                \n",
    "                       'masks': {'shape': (IMAGE_SIZE, IMAGE_SIZE, 2),\n",
    "                                 'type': 'int32',\n",
    "                                 'data_format': 'channels_last',\n",
    "                                 'name': 'targets'}\n",
    "                       }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create model_config.\n",
    "* '<b>inputs</b>' - dict of placeholders configs\n",
    "* '<b>batch_norm</b>' - enable batch normalization\n",
    "* '<b>n_blocks</b>' - number of encoding/decoding blocks (4 by default)\n",
    "* '<b>n_filters</b>' - number of filters after the first convolution (64 by default)\n",
    "* '<b>outputs</b>' - dict of operations to add into graph\n",
    "* '<b>loss</b>' - loss function\n",
    "* '<b>optimizer</b>' - loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_config = {'inputs': placeholders_config,\n",
    "                'batch_norm': {'momentum': 0.1},\n",
    "                'n_blocks': 4,\n",
    "                'n_filters': 64,\n",
    "                'output': dict(ops=['proba']),\n",
    "                'loss': 'softmax_cross_entropy',\n",
    "                'optimizer': 'Adam'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create feed dicts. The key is name of the tensor in tf graph, value is batch component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feed_dict = {'images': B('images'),\n",
    "                   'masks': B('masks')}        \n",
    "\n",
    "test_feed_dict = {'images': B('images'),\n",
    "                  'masks': B('masks')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def demonstrate_model(model):\n",
    "    print('Create pipelines...')\n",
    "\n",
    "    ppl_train = ((load_template << mnistset.train)                         # load data from file\n",
    "            .add_noise()                                                   # add MNIST-noise to images\n",
    "            .init_model('static', model, 'NN', config=model_config)\n",
    "            .train_model('NN',                                             # model name\n",
    "                         feed_dict=train_feed_dict))\n",
    "\n",
    "    print('Start training...')\n",
    "    start = time()\n",
    "    for i in range(MAX_ITER):\n",
    "        ppl_train.next_batch(BATCH_SIZE, n_epochs=None, shuffle=True)\n",
    "    stop = time()\n",
    "    linknet_time = (stop - start) / 60\n",
    "    print(\"Train time: {:05.3f} min\".format((stop-start)/60))\n",
    "\n",
    "    ppl_test = ((load_template << mnistset.test)                       \n",
    "             .add_noise()                   \n",
    "             .import_model('NN', ppl_train)\n",
    "             .init_variable('predictions', init_on_each_run=list)\n",
    "             .predict_model('NN',                                      \n",
    "                           fetches=model.__name__+'/predicted_proba',\n",
    "                           feed_dict=test_feed_dict,\n",
    "                           save_to=V('predictions'),\n",
    "                           mode='a'))\n",
    "\n",
    "    batch = ppl_test.next_batch(100, n_epochs=None)\n",
    "    images = batch.data.images\n",
    "    masks = batch.data.masks\n",
    "    noise = batch.data.noise\n",
    "    predictions = ppl_test.get_variable('predictions')[-1]\n",
    "\n",
    "    intersection = np.sum(np.logical_and((predictions[:,:,:,1] > 0.5), masks[:,:,:,1]))\n",
    "    union = np.sum(np.logical_or((predictions[:,:,:,1] > 0.5), masks[:,:,:,1]))\n",
    "    iou = intersection / union\n",
    "    print('Test IoU: {0:.3f}'.format(iou))\n",
    "\n",
    "    plot_examples_highlighted(images, noise, masks, predictions, 5, model.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create pipelines...\n",
      "Start training...\n"
     ]
    }
   ],
   "source": [
    "demonstrate_model(UNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrate_model(LinkNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrate_model(FCN32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demonstrate_model(FCN8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
