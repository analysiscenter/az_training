{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ImagesBatch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b68d8de58753>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDatasetIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minbatch_parallel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImagesBatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'ImagesBatch'"
     ]
    }
   ],
   "source": [
    "\"\"\" Custom batch class for storing mnist batch and models\n",
    "\n",
    "\"\"\"\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import blosc\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import blosc\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "from dataset import DatasetIndex, Dataset\n",
    "\n",
    "from dataset import Batch, action, model, inbatch_parallel, ImagesBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistBatch(ImagesBatch):\n",
    "    \"\"\" Mnist batch and models\n",
    "    \"\"\"\n",
    "    def __init__(self, index, *args, **kwargs):\n",
    "        \"\"\" Init func, inherited from base batch\n",
    "        \"\"\"\n",
    "        super().__init__(index, *args, **kwargs)\n",
    "        self.images = None\n",
    "        self.labels = None\n",
    "\n",
    "\n",
    "\n",
    "    def post_function(self, list_results):\n",
    "        '''Post function for parallel shift, gathers results of every worker'''\n",
    "        result_batch = np.array(list_results)\n",
    "        self.images = result_batch\n",
    "        return self\n",
    "\n",
    "    def init_function(self):\n",
    "        '''Init function for parallel shift\n",
    "        returns list of indices, each of them will be sent to the worker separately\n",
    "        '''\n",
    "        return range(self.images.shape[0])\n",
    "\n",
    "    @action\n",
    "    @inbatch_parallel(init='init_function', post='post_function', target='threads')\n",
    "    def shift_flattened_pic(self, idx, max_margin=8):\n",
    "        \"\"\" Apply random shift to a flattened pic\n",
    "        \n",
    "        Args:\n",
    "            pic: ndarray of shape=(784) representing a pic to be flattened\n",
    "        Return:\n",
    "            flattened shifted pic\n",
    "        \"\"\"\n",
    "        \n",
    "        pic = self.images[idx]\n",
    "        padded = np.pad(pic, pad_width=[[max_margin, max_margin], [max_margin, max_margin]], \n",
    "                        mode='minimum')\n",
    "        left_lower = np.random.randint(2 * max_margin, size=2)\n",
    "        slicing = (slice(left_lower[0], left_lower[0] + 28),\n",
    "                   slice(left_lower[1], left_lower[1] + 28))\n",
    "        res = padded[slicing]\n",
    "        return res\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def components(self):\n",
    "        \"\"\" Components of mnist-batch\n",
    "        \"\"\"\n",
    "        return 'images', 'labels'\n",
    "\n",
    "    @action\n",
    "    def load(self, src, fmt='blosc'):\n",
    "        \"\"\" Load mnist pics with specifed indices\n",
    "\n",
    "        Args:\n",
    "            fmt: format of source. Can be either 'blosc' or 'ndarray'\n",
    "            src: if fmt='blosc', then src is a path to dir with blosc-packed\n",
    "                mnist images and labels are stored.\n",
    "                if fmt='ndarray' - this is a tuple with arrays of images and labels\n",
    "\n",
    "        Return:\n",
    "            self\n",
    "        \"\"\"\n",
    "        if fmt == 'blosc':     \n",
    "            # read blosc images, labels\n",
    "            with open('mnist_pics.blk', 'rb') as file:\n",
    "                self.images = blosc.unpack_array(file.read())[self.indices]\n",
    "                self.images = np.reshape(self.images, (65000, 28, 28))\n",
    "\n",
    "            with open('mnist_labels.blk', 'rb') as file:\n",
    "                self.labels = blosc.unpack_array(file.read())[self.indices]\n",
    "        elif fmt == 'ndarray':\n",
    "            all_images, all_labels = src\n",
    "            self.images = all_images[self.indices]\n",
    "            self.labels = all_labels[self.indices]\n",
    "\n",
    "        return self\n",
    "\n",
    "    @model()\n",
    "    def convy(mode='dynamic'):\n",
    "        \"\"\" Conv-net mnist classifier\n",
    "\n",
    "        Args:\n",
    "            ___\n",
    "        Return:\n",
    "            [[placeholder for input, ph for true labels, loss, train_step],\n",
    "             [true categorical labels, categorical_hat labels, accuracy]]\n",
    "        \"\"\"\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            # build the net\n",
    "            training = tf.placeholder(tf.bool, shape=[], name='mode')\n",
    "            x = tf.placeholder(tf.float32, [None, 28, 28], name='x')\n",
    "            x_as_pics = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "\n",
    "            net = tf.layers.conv2d(x_as_pics, filters=4, kernel_size=(7,7), strides=(1, 1), padding='same')\n",
    "            net = tf.layers.max_pooling2d(net, pool_size=(6, 6), strides=(2, 2), padding='same')\n",
    "            net = tf.layers.batch_normalization(net, training=training)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "            net = tf.layers.conv2d(net, filters=16, kernel_size=(5, 5), strides=(1, 1), padding='same')\n",
    "            net = tf.layers.max_pooling2d(net, pool_size=(5, 5), strides=(2, 2), padding='same')\n",
    "            net = tf.layers.batch_normalization(net, training=training)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "\n",
    "            net = tf.layers.conv2d(net, filters=32, kernel_size=(3, 3), strides=(1, 1), padding='same')\n",
    "            net = tf.layers.max_pooling2d(net, pool_size=(2, 2), strides=(2, 2), padding='same')\n",
    "            net = tf.layers.batch_normalization(net, training=training)\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "\n",
    "            net = tf.contrib.layers.flatten(net)\n",
    "\n",
    "            # dropout \n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            # net = tf.nn.dropout(net, keep_prob)\n",
    "\n",
    "\n",
    "            net = tf.layers.dense(net, 128, kernel_initializer=tf.truncated_normal_initializer(0.0, 1))\n",
    "    #         net = tf.layers.dense(net, 128, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "\n",
    "            net = tf.nn.relu(net)\n",
    "\n",
    "            net = tf.layers.dense(net, 10, kernel_initializer=tf.truncated_normal_initializer(0.0, 1))\n",
    "    #         net = tf.layers.dense(net, 10, kernel_initializer=tf.contrib.layers.xavier_initializer(uniform=False))\n",
    "\n",
    "            probs = tf.nn.softmax(logits=net, name='softmax_output')\n",
    "\n",
    "            # placeholder for correct labels\n",
    "            y_ = tf.placeholder(tf.float32, [None, 10], name='y_')\n",
    "\n",
    "            # loss\n",
    "    #         loss = tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=y_, name='loss')\n",
    "            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=net, labels=y_, name='loss'))\n",
    "\n",
    "            global_step = tf.Variable(0, trainable=False)\n",
    "            starter_learning_rate = 0.0001\n",
    "\n",
    "            learning_rate = tf.placeholder(tf.float32, shape=[], name='lr')\n",
    "            # learning_rate = tf.train.exponential_decay(starter_learning_rate, global_step,\n",
    "            #                                           100, 0.85, staircase=True)\n",
    "\n",
    "            # optimization step\n",
    "            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "            with tf.control_dependencies(update_ops):\n",
    "                train_step = (\n",
    "                    tf.train.GradientDescentOptimizer(learning_rate)\n",
    "                    .minimize(loss, global_step=global_step)\n",
    "                    )\n",
    "\n",
    "            # stats\n",
    "            labels_hat = tf.cast(tf.argmax(net, axis=1), tf.float32, name='labels_hat')\n",
    "            labels = tf.cast(tf.argmax(y_, axis=1), tf.float32, name='labels')\n",
    "            accuracy = tf.reduce_mean(tf.cast(tf.equal(labels_hat, labels), tf.float32), name='accuracy')\n",
    "\n",
    "            softmax = tf.placeholder(tf.float32, [None, 10], name='softmax')\n",
    "\n",
    "            predicts = tf.placeholder(tf.float32, [None, 10], name='predicts')\n",
    "            test_acc = tf.reduce_mean(tf.cast(tf.equal(predicts, labels), tf.float32), name='accuracy')\n",
    "\n",
    "            print_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=softmax, labels=y_, name='print_loss'))\n",
    "            \n",
    "            cyclic_learning_rate = alpha / tf.cast(2.0, tf.float32) * \n",
    "                (tf.cos(tf.cast(np.pi, tf.float32) * ((tf.cast(global_step, tf.float32) - 1) % (period)) / (period)) + 1)          \n",
    "\n",
    "            sess = tf.Session()\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        return [[x, y_, loss, train_step, training, keep_prob], [labels, labels_hat, accuracy], [probs],\n",
    "                [learning_rate, global_step, print_loss], [softmax, predicts, test_acc], [sess], [cyclic_learning_rate]]\n",
    "\n",
    "    @action(model='convy')\n",
    "    def predict(self, model, pics, y_true, y_predict, probabilities):\n",
    "        ''' Predict labels '''\n",
    "        sess = model[5][0]\n",
    "        x, y_, _, _, training, keep_prob = model[0]\n",
    "        labels, labels_hat, _ = model[1]\n",
    "        probs = model[2][0]\n",
    "        probabilities.append(sess.run(probs, feed_dict={x:self.images, training: False, keep_prob: 1.0}))\n",
    "        y_predict.append(sess.run(labels_hat, feed_dict={x:self.images, training: False, keep_prob: 1.0}))\n",
    "        y_true.append(sess.run(labels, feed_dict={y_:self.labels}))\n",
    "        pics.append(self.images)\n",
    "        return self\n",
    "\n",
    "    @action(model='convy')\n",
    "    def train_convy(self, model, alpha, period, n_iterations, accs, loss_history):\n",
    "        \"\"\" Train-action for convy-model\n",
    "\n",
    "        Args:\n",
    "            model: do not supply this arg, always the output of convy-model defined above\n",
    "            sess: tf-session in which learning variables are to be updated\n",
    "        \"\"\"        \n",
    "        sess = model[5][0]\n",
    "        cyclic_learning_rate = model[6][0]\n",
    "        x, y_, loss, train_step, training, keep_prob = model[0]\n",
    "        learning_rate, global_step, _ = model[3]\n",
    "        \n",
    "        _, _, accuracy = model[1]\n",
    "\n",
    "        alpha = tf.cast(alpha, tf.float32)\n",
    "        \n",
    "        global_step = sess.run(global_step)\n",
    "    \n",
    "        period = tf.cast(period, tf.float32)\n",
    "        n_iterations = tf.cast(n_iterations, tf.float32)\n",
    "        n_cycles = n_iterations // period\n",
    "        \n",
    "        \n",
    "        cyclic_learning_rate = sess.run(cyclic_learning_rate)\n",
    "        # print ('HHHHHHHHEEEEEEEEEEEY', cyclic_learning_rate)\n",
    "        sess.run(train_step, feed_dict={x: self.images, y_: self.labels, training: True, keep_prob: 0.7, learning_rate:cyclic_learning_rate})        \n",
    "        \n",
    "        period = sess.run(period)\n",
    "        \n",
    "        if (global_step) % period == 0:\n",
    "            if global_step == 0:\n",
    "                pass\n",
    "            else:\n",
    "                print ('hey')\n",
    "                saver = tf.train.Saver(name=str(global_step))\n",
    "                address = 'trained' + '+' + str(global_step) + '/model'\n",
    "                saver.save(sess, address, global_step=global_step)\n",
    "        \n",
    "#         if global_step == (n_iterations - 1):\n",
    "#             print ('hey')\n",
    "#             saver = tf.train.Saver()\n",
    "#             saver.save(sess, 'trained/model', global_step=global_step)\n",
    "\n",
    "        \n",
    "        loss_history.append(sess.run(loss, feed_dict={x: self.images, y_: self.labels, training: False, keep_prob: 1.0}))\n",
    "\n",
    "        accs.append(sess.run(accuracy, feed_dict={x: self.images, y_: self.labels, training: False, keep_prob: 1.0}))\n",
    "\n",
    "        return self\n",
    "\n",
    "    \n",
    "#     @model()\n",
    "#     def ensemble():\n",
    "#         ''' Classifier which averages prediction from m models loaded from the disk \n",
    "#             Args:\n",
    "#             __\n",
    "#             Returns:\n",
    "#         '''\n",
    "#         n_cycles = n_iterations // period\n",
    "#         results = []\n",
    "#         for i in range(1, n_cycles + 1):\n",
    "#             address = 'trained/model' + '-' + str(i*period) + '.meta'\n",
    "\n",
    "#             grapphy_2 = tf.Graph()\n",
    "#             with grapphy_2.as_default():\n",
    "#                 new_sess = tf.Session()\n",
    "\n",
    "#                 new_saver = tf.train.import_meta_graph(address)\n",
    "#                 new_saver.restore(new_sess, tf.train.latest_checkpoint('trained/'))\n",
    "#                 training = grapphy_2.get_tensor_by_name('mode:0')\n",
    "#                 x = grapphy_2.get_tensor_by_name('x:0')\n",
    "#                 softmax_output = grapphy_2.get_tensor_by_name('softmax_output:0')\n",
    "\n",
    "#                 res = new_sess.run(softmax_output, feed_dict={x:imgs, training:False})\n",
    "#                 results.append(res)\n",
    "                \n",
    "#         return results\n",
    "            \n",
    "\n",
    "    \n",
    "#     @action(model='ensemble')\n",
    "#     def update_stats(self, model):\n",
    "#         results = model\n",
    "        \n",
    "    \n",
    "    @action(model='convy')\n",
    "    def update_stats(self, model, period, n_iterations, accs, loss_history):\n",
    "        \"\"\" Append accuracy that is obtained by convy-model given weights stored in sess Tf-session\n",
    "\n",
    "        Args:\n",
    "            model: do not supply this arg, always the output of convy-model defined above\n",
    "            sess: tf-session with trained (to some extent) weights\n",
    "            accs: list with accuracies\n",
    "        \"\"\"\n",
    "        sess = model[5][0]\n",
    "        n_cycles = n_iterations // period\n",
    "        results = []\n",
    "        for i in range(1, n_cycles + 1):\n",
    "            address = 'trained/model' + '-' + str(i*period) + '.meta'\n",
    "\n",
    "            grapphy_2 = tf.Graph()\n",
    "            with grapphy_2.as_default():\n",
    "                new_sess = tf.Session()\n",
    "\n",
    "                new_saver = tf.train.import_meta_graph(address)\n",
    "                new_saver.restore(new_sess, tf.train.latest_checkpoint('trained/'))\n",
    "                training = grapphy_2.get_tensor_by_name('mode:0')\n",
    "                x = grapphy_2.get_tensor_by_name('x:0')\n",
    "                softmax_output = grapphy_2.get_tensor_by_name('softmax_output:0')\n",
    "\n",
    "                res = new_sess.run(softmax_output, feed_dict={x:imgs, training:False})\n",
    "                results.append(res)\n",
    "            \n",
    "        avg_softmax = np.average(results, axis=0)\n",
    "        my_predicts = np.argmax(a, axis=1)\n",
    "        \n",
    "        \n",
    "        labels = np.argmax(self.labels, axis=1)\n",
    "        \n",
    "        \n",
    "        _, _, accuracy = model[1]\n",
    "        x, y_, _, _, training, keep_prob = model[0]\n",
    "        _, _, print_loss = model[3]\n",
    "        softmax, predicts, test_acc = model[4]\n",
    "        \n",
    "        loss_history.append(sess.run(print_loss, feed_dict={softmax: avg_softmax, y_: self.labels, training: False, keep_prob: 1.0}))\n",
    "\n",
    "        accs.append(sess.run(accuracy, feed_dict={predicts: my_predicts, y_: self.labels, training: False, keep_prob: 1.0}))\n",
    "        return self\n",
    "\n",
    "    \n",
    "#     @action(model='convy')\n",
    "#     def update_stats(self, model, sess, accs, loss_history):\n",
    "#         \"\"\" Append accuracy that is obtained by convy-model given weights stored in sess Tf-session\n",
    "\n",
    "#         Args:\n",
    "#             model: do not supply this arg, always the output of convy-model defined above\n",
    "#             sess: tf-session with trained (to some extent) weights\n",
    "#             accs: list with accuracies\n",
    "#         \"\"\"\n",
    "        \n",
    "        \n",
    "#         _, _, accuracy = model[1]\n",
    "#         x, y_, _, _, training, keep_prob = model[0]\n",
    "#         _, _, print_loss = model[3]\n",
    "#         loss_history.append(sess.run(print_loss, feed_dict={x: self.images, y_: self.labels, training: False, keep_prob: 1.0}))\n",
    "\n",
    "#         accs.append(sess.run(accuracy, feed_dict={x: self.images, y_: self.labels, training: False, keep_prob: 1.0}))\n",
    "#         return self\n",
    "\n",
    "\n",
    "def draw_stats(stats, title):\n",
    "    plt.title(title)\n",
    "    plt.plot(stats)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%env CUDA_VISIBLE_DEVICES = 1\n",
    "\n",
    "src = 'C:/Users/Dari/Documents/az_training/task_03'\n",
    "\n",
    "with open(os.path.join(src, 'mnist_pics.blk'), 'rb') as file:\n",
    "    full_imgs = blosc.unpack_array(file.read())\n",
    "    \n",
    "with open(os.path.join(src, 'mnist_labels.blk'), 'rb') as file:\n",
    "    full_labs = blosc.unpack_array(file.read())\n",
    "    \n",
    "src = (np.reshape(full_imgs, (65000, 28, 28)), full_labs)\n",
    "\n",
    "LEN_MNIST = 65000\n",
    "indy = DatasetIndex(np.arange(LEN_MNIST))\n",
    "\n",
    "mnistset = Dataset(indy, batch_class=MnistBatch)\n",
    "mnistset.cv_split([0.9, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs, lbls = src\n",
    "imgs = imgs[:100, :, :]\n",
    "lbls = lbls[:100, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sess = tf.Session()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "stats = []\n",
    "loss_history = []\n",
    "\n",
    "alpha = 0.001\n",
    "period = 200\n",
    "n_iterations = 401\n",
    "\n",
    "train_loss_history = [] \n",
    "train_stats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline for train\n",
    "ppl = (mnistset.train.pipeline().\n",
    "       load(src=src, fmt='ndarray').\n",
    "       train_convy(alpha, period, n_iterations, train_stats, train_loss_history))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f():\n",
    "    ppl = (mnistset.train.pipeline().\n",
    "        load(src=src, fmt='ndarray').\n",
    "        train_convy(alpha, period, n_iterations, train_stats, train_loss_history))\n",
    "\n",
    "    for i in tqdm(range(n_iterations)):\n",
    "        ppl.next_batch(100, n_epochs=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/401 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Fetch argument <tf.Tensor 'mul_3:0' shape=() dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"mul_3:0\", shape=(), dtype=float32) is not an element of this graph.)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    266\u001b[0m         self._unique_fetches.append(ops.get_default_graph().as_graph_element(\n\u001b[1;32m--> 267\u001b[1;33m             fetch, allow_tensor=True, allow_operation=True))\n\u001b[0m\u001b[0;32m    268\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mas_graph_element\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2583\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2584\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_as_graph_element_locked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_operation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_as_graph_element_locked\u001b[1;34m(self, obj, allow_tensor, allow_operation)\u001b[0m\n\u001b[0;32m   2662\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2663\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tensor %s is not an element of this graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2664\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor Tensor(\"mul_3:0\", shape=(), dtype=float32) is not an element of this graph.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0ec059b9bfe1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-96db9fcacee6>\u001b[0m in \u001b[0;36mf\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mppl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Dari\\Documents\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36mnext_batch\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    684\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_generator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m             \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lazy_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Documents\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36mgen_batch\u001b[1;34m(self, batch_size, shuffle, n_epochs, drop_last, prefetch, *args, **kwargs)\u001b[0m\n\u001b[0;32m    660\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbatch_generator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 662\u001b[1;33m                     \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    663\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mSkipBatchException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    664\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Documents\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec\u001b[1;34m(self, batch, new_loop)\u001b[0m\n\u001b[0;32m    422\u001b[0m             \u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masyncio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 424\u001b[1;33m         \u001b[0mbatch_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_all_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    425\u001b[0m         \u001b[0mbatch_res\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch_res\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Documents\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec_all_actions\u001b[1;34m(self, batch, action_list)\u001b[0m\n\u001b[0;32m    406\u001b[0m                     \u001b[0mjoin_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec_one_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_action_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'kwargs'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m'tf_queue'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_action\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Documents\\az_training\\dataset\\dataset\\pipeline.py\u001b[0m in \u001b[0;36m_exec_one_action\u001b[1;34m(self, batch, action, args, kwargs)\u001b[0m\n\u001b[0;32m    364\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[0maction_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_action_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m                 \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Documents\\az_training\\dataset\\dataset\\decorators.py\u001b[0m in \u001b[0;36m_action_wrapper\u001b[1;34m(action_self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m             \u001b[0m_model_spec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_model_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 256\u001b[1;33m             \u001b[0m_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_self\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_model_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_use_lock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-f90ed8c25a36>\u001b[0m in \u001b[0;36mtrain_convy\u001b[1;34m(self, model, alpha, period, n_iterations, accs, loss_history)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0mcyclic_learning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mperiod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mperiod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mcyclic_learning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcyclic_learning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[1;31m# print ('HHHHHHHHEEEEEEEEEEEY', cyclic_learning_rate)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mcyclic_learning_rate\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    982\u001b[0m     \u001b[1;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[1;32m--> 984\u001b[1;33m         self._graph, fetches, feed_dict_string, feed_handles=feed_handles)\n\u001b[0m\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    986\u001b[0m     \u001b[1;31m# Run request and get response.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[0;32m    408\u001b[0m     \"\"\"\n\u001b[0;32m    409\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[1;34m(fetch)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m           \u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0m_ElementFetchMapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontraction_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m     \u001b[1;31m# Did not find anything.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     raise TypeError('Fetch argument %r has invalid type %r' %\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, fetches, contraction_fn)\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n\u001b[1;32m--> 274\u001b[1;33m                          'Tensor. (%s)' % (fetch, str(e)))\n\u001b[0m\u001b[0;32m    275\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m         raise ValueError('Fetch argument %r cannot be interpreted as a '\n",
      "\u001b[1;31mValueError\u001b[0m: Fetch argument <tf.Tensor 'mul_3:0' shape=() dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"mul_3:0\", shape=(), dtype=float32) is not an element of this graph.)"
     ]
    }
   ],
   "source": [
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'conv2d/kernel:0' shape=(7, 7, 1, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d/bias:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization/beta:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization/gamma:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization/moving_mean:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization/moving_variance:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/kernel:0' shape=(5, 5, 4, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_1/bias:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/moving_mean:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_1/moving_variance:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_2/kernel:0' shape=(3, 3, 16, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'conv2d_2/bias:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_2/beta:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_2/gamma:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_2/moving_mean:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'batch_normalization_2/moving_variance:0' shape=(32,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/kernel:0' shape=(512, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dense/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/kernel:0' shape=(128, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=int32_ref>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graphs = {}\n",
    "for i in range(2):\n",
    "    graphs['model'+ str(i)] =  i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model0': 0, 'model1': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_cycles = 2\n",
    "period = 200\n",
    "# for i in tqdm(range(n_iterations)):\n",
    "#     # ppl.next_batch(100, n_epochs=None)\n",
    "#     #ppl_test.next_batch(100, n_epochs=None)\n",
    "\n",
    "results = []\n",
    "xs = []\n",
    "sos = []\n",
    "\n",
    "grapphy_2 = tf.Graph()\n",
    "graphs = {}\n",
    "for i in range(1, n_cycles + 1):\n",
    "    graphs['model'+ str(i)] = tf.Graph()\n",
    "\n",
    "    with graphs['model'+ str(i)].as_default():\n",
    "        new_sess = tf.Session()\n",
    "        \n",
    "    \n",
    "    for i in range(1, n_cycles + 1):\n",
    "    #         with tf.variable_scope(str(n_cycles)):\n",
    "        folder = 'trained+' + str(i*period) + '/'\n",
    "        address = folder + 'model' + '-' + str(i*period) + '.meta'\n",
    "        print ('current', address)\n",
    "    #                 new_saver = tf.train.import_meta_graph(address)\n",
    "    #                 new_saver.restore(new_sess, tf.train.latest_checkpoint('trained/'))\n",
    "\n",
    "    #     grapphy_2 = tf.Graph()\n",
    "    #     with grapphy_2.as_default():\n",
    "    # #                 new_sess = tf.Session(graph=grapphy_2)\n",
    "    #         new_sess = tf.Session()\n",
    "        \n",
    "        \n",
    "        new_saver = tf.train.import_meta_graph(address)\n",
    "        new_saver.restore(new_sess, tf.train.latest_checkpoint(folder))\n",
    "        with tf.variable_scope(str(i)):\n",
    "            training = grapphy_2.get_tensor_by_name('mode:0')\n",
    "            x = grapphy_2.get_tensor_by_name('x:0')\n",
    "            softmax_output = grapphy_2.get_tensor_by_name('softmax_output:0')\n",
    "            xs.append(x)\n",
    "            sos.append(softmax_output)\n",
    "        \n",
    "        #res = new_sess.run(softmax_output, feed_dict={x:imgs, training:False})\n",
    "        # results.append(res)\n",
    "        # print (res.shape)\n",
    "\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current trained+200/model-200.meta\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "invalid group reference 11 at position 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-6f2fda37adfc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mnew_saver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimport_meta_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m             \u001b[0mnew_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_sess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\u001b[0m in \u001b[0;36mimport_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, import_scope, **kwargs)\u001b[0m\n\u001b[0;32m   1684\u001b[0m                                       \u001b[0mclear_devices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclear_devices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1685\u001b[0m                                       \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1686\u001b[1;33m                                       **kwargs)\n\u001b[0m\u001b[0;32m   1687\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHasField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saver_def\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1688\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\meta_graph.py\u001b[0m in \u001b[0;36mimport_scoped_meta_graph\u001b[1;34m(meta_graph_or_file, clear_devices, graph, import_scope, input_map, unbound_inputs_col_name, restore_collections_predicate)\u001b[0m\n\u001b[0;32m    528\u001b[0m           \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParseFromString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m           graph.add_to_collection(\n\u001b[1;32m--> 530\u001b[1;33m               key, from_proto(proto, import_scope=scope_to_prepend_to_names))\n\u001b[0m\u001b[0;32m    531\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m         \u001b[0mfield\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_from_proto_fn\u001b[1;34m(v, import_scope)\u001b[0m\n\u001b[0;32m    516\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_resource\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mResourceVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36mfrom_proto\u001b[1;34m(variable_def, import_scope)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[1;34m\"\"\"Returns a `Variable` object created from `variable_def`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m     return Variable(variable_def=variable_def,\n\u001b[1;32m--> 785\u001b[1;33m                     import_scope=import_scope)\n\u001b[0m\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0mSaveSliceInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope)\u001b[0m\n\u001b[0;32m    187\u001b[0m         raise ValueError(\"variable_def and initial_value are mutually \"\n\u001b[0;32m    188\u001b[0m                          \"exclusive.\")\n\u001b[1;32m--> 189\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m       \u001b[1;31m# Create from initial_value.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_init_from_proto\u001b[1;34m(self, variable_def, import_scope)\u001b[0m\n\u001b[0;32m    336\u001b[0m     self._variable = g.as_graph_element(\n\u001b[0;32m    337\u001b[0m         ops.prepend_name_scope(variable_def.variable_name,\n\u001b[1;32m--> 338\u001b[1;33m                                import_scope=import_scope))\n\u001b[0m\u001b[0;32m    339\u001b[0m     self._initializer_op = g.as_graph_element(\n\u001b[0;32m    340\u001b[0m         ops.prepend_name_scope(variable_def.initializer_name,\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mprepend_name_scope\u001b[1;34m(name, import_scope)\u001b[0m\n\u001b[0;32m   4402\u001b[0m       \u001b[0mstr_to_replace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mr\"([\\^]|loc:@|^)(.*)\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4403\u001b[0m       return re.sub(str_to_replace, r\"\\1\" + import_scope + r\"/\\2\",\n\u001b[1;32m-> 4404\u001b[1;33m                     compat.as_str(name))\n\u001b[0m\u001b[0;32m   4405\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4406\u001b[0m       \u001b[1;31m# If the name is not of a type we can process, simply return it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mpassed\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmatch\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmust\u001b[0m \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m     a replacement string to be used.\"\"\"\n\u001b[1;32m--> 191\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msubn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_subx\u001b[1;34m(pattern, template)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_subx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[1;31m# internal: pattern.sub/subn implementation helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m     \u001b[0mtemplate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# literal replacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile_repl\u001b[1;34m(repl, pattern)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_compile_repl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;31m# internal: compile replacement pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msre_parse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_template\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36mparse_template\u001b[1;34m(source, pattern)\u001b[0m\n\u001b[0;32m    942\u001b[0m                         \u001b[0mlappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    943\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misoctal\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 944\u001b[1;33m                     \u001b[0maddgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    945\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Dari\\Anaconda3\\lib\\sre_parse.py\u001b[0m in \u001b[0;36maddgroup\u001b[1;34m(index, pos)\u001b[0m\n\u001b[0;32m    886\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0maddgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 888\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"invalid group reference %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    889\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mliteral\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[0mliterals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliteral\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: invalid group reference 11 at position 1"
     ]
    }
   ],
   "source": [
    "n_cycles = 2\n",
    "period = 200\n",
    "# for i in tqdm(range(n_iterations)):\n",
    "#     # ppl.next_batch(100, n_epochs=None)\n",
    "#     #ppl_test.next_batch(100, n_epochs=None)\n",
    "\n",
    "results = []\n",
    "xs = []\n",
    "sos = []\n",
    "\n",
    "grapphy_2 = tf.Graph()\n",
    "\n",
    "new_sess = tf.Session()\n",
    "\n",
    "with grapphy_2.as_default():\n",
    "    new_sess = tf.Session()\n",
    "\n",
    "    \n",
    "    for i in range(1, n_cycles + 1):\n",
    "    #         with tf.variable_scope(str(n_cycles)):\n",
    "        folder = 'trained+' + str(i*period) + '/'\n",
    "        address = folder + 'model' + '-' + str(i*period) + '.meta'\n",
    "        print ('current', address)\n",
    "    #                 new_saver = tf.train.import_meta_graph(address)\n",
    "    #                 new_saver.restore(new_sess, tf.train.latest_checkpoint('trained/'))\n",
    "\n",
    "    #     grapphy_2 = tf.Graph()\n",
    "    #     with grapphy_2.as_default():\n",
    "    # #                 new_sess = tf.Session(graph=grapphy_2)\n",
    "    #         new_sess = tf.Session()\n",
    "        \n",
    "        \n",
    "        new_saver = tf.train.import_meta_graph(address)\n",
    "        new_saver.restore(new_sess, tf.train.latest_checkpoint(folder))\n",
    "        with tf.variable_scope(str(i)):\n",
    "            training = grapphy_2.get_tensor_by_name('mode:0')\n",
    "            x = grapphy_2.get_tensor_by_name('x:0')\n",
    "            softmax_output = grapphy_2.get_tensor_by_name('softmax_output:0')\n",
    "            xs.append(x)\n",
    "            sos.append(softmax_output)\n",
    "        \n",
    "        #res = new_sess.run(softmax_output, feed_dict={x:imgs, training:False})\n",
    "        # results.append(res)\n",
    "        # print (res.shape)\n",
    "\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for i in range(2):\n",
    "    res = new_sess.run(sos[i], feed_dict={xs[i]:imgs, training:False})\n",
    "    results.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14588"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(grapphy_2.get_operations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from trained/model-800\n",
      "(100, 10)\n",
      "INFO:tensorflow:Restoring parameters from trained/model-800\n",
      "(100, 10)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "n_cycles = 2\n",
    "period = 200\n",
    "# for i in tqdm(range(n_iterations)):\n",
    "#     # ppl.next_batch(100, n_epochs=None)\n",
    "#     #ppl_test.next_batch(100, n_epochs=None)\n",
    "\n",
    "results_2 = []\n",
    "for i in range(1, n_cycles + 1):\n",
    "#         with tf.variable_scope(str(n_cycles)):\n",
    "    address = 'trained/model' + '-' + str(i*period) + '.meta'\n",
    "#                 new_saver = tf.train.import_meta_graph(address)\n",
    "#                 new_saver.restore(new_sess, tf.train.latest_checkpoint('trained/'))\n",
    "\n",
    "    #address = 'trained/model-200.meta'\n",
    "    grapphy_2 = tf.Graph()\n",
    "    with grapphy_2.as_default():\n",
    "#                 new_sess = tf.Session(graph=grapphy_2)\n",
    "        new_sess = tf.Session()\n",
    "\n",
    "        new_saver = tf.train.import_meta_graph(address)\n",
    "        new_saver.restore(new_sess, tf.train.latest_checkpoint('trained/'))\n",
    "        training = grapphy_2.get_tensor_by_name('mode:0')\n",
    "        x = grapphy_2.get_tensor_by_name('x:0')\n",
    "        softmax_output = grapphy_2.get_tensor_by_name('softmax_output:0')\n",
    "        # new_sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        res = new_sess.run(softmax_output, feed_dict={x:imgs, training:False})\n",
    "        results_2.append(res)\n",
    "        print (res.shape)\n",
    "print ('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[1] - results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.76795414e-08,   6.81321263e-01,   3.06836754e-01,\n",
       "          8.99909555e-14,   1.17666749e-02,   2.47535610e-08,\n",
       "          6.57234050e-05,   2.13701323e-09,   9.40783320e-06,\n",
       "          1.26009141e-07],\n",
       "       [  9.87879139e-06,   6.08795047e-01,   4.42498066e-02,\n",
       "          2.24613488e-01,   4.54826327e-03,   4.45917994e-03,\n",
       "          1.54893333e-03,   6.35941476e-02,   4.71648276e-02,\n",
       "          1.01629691e-03],\n",
       "       [  3.13311205e-07,   1.84587859e-10,   1.43421719e-13,\n",
       "          1.83362367e-19,   9.99999642e-01,   1.61236004e-15,\n",
       "          3.55248062e-08,   1.26390705e-28,   4.41992409e-21,\n",
       "          4.10349380e-14],\n",
       "       [  4.07662071e-10,   4.44246171e-27,   2.07320393e-23,\n",
       "          2.49694592e-25,   7.86778559e-26,   1.55530946e-35,\n",
       "          1.24471696e-34,   1.06452911e-11,   2.60874939e-28,\n",
       "          1.00000000e+00],\n",
       "       [  2.21930793e-03,   9.92611229e-01,   6.83569760e-06,\n",
       "          2.93956390e-07,   1.70885539e-03,   2.09651282e-16,\n",
       "          3.31501896e-03,   9.11315667e-17,   1.38509655e-04,\n",
       "          5.86568825e-13],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00787563e-19,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   6.02151848e-34,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   4.28659919e-38,\n",
       "          0.00000000e+00,   4.43082791e-30,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  4.53366351e-33,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.05921270e-37,   1.47216973e-31,   1.86674940e-23,\n",
       "          3.54904239e-30,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          8.81524993e-30,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   9.17665803e-38,   1.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   3.97703626e-34,\n",
       "          1.00000000e+00,   0.00000000e+00,   1.28610490e-21,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   5.19746088e-23,\n",
       "          0.00000000e+00,   9.91976760e-29,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.00479163e-25,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          3.62804622e-34,   1.00392665e-20,   8.75570508e-28,\n",
       "          3.37522237e-15,   1.17489599e-28,   2.40994840e-28,\n",
       "          0.00000000e+00],\n",
       "       [  8.21019803e-15,   6.86004459e-27,   6.51448161e-14,\n",
       "          1.63177434e-26,   9.99999881e-01,   2.03641398e-20,\n",
       "          1.65309666e-09,   2.03376269e-24,   6.65806019e-30,\n",
       "          8.52277324e-08],\n",
       "       [  8.68439945e-32,   6.42735208e-27,   3.30260152e-13,\n",
       "          2.22040455e-07,   8.05796270e-25,   5.67039457e-17,\n",
       "          9.99999762e-01,   6.14490309e-17,   1.03240354e-17,\n",
       "          1.34830496e-20],\n",
       "       [  3.07697051e-14,   3.46646084e-32,   1.78573936e-21,\n",
       "          1.02864130e-21,   1.11998096e-26,   9.83777285e-01,\n",
       "          1.62227619e-02,   1.38986660e-27,   2.76457691e-26,\n",
       "          4.61097560e-09],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.17004853e-19,   2.45462089e-37,   1.47520236e-35,\n",
       "          0.00000000e+00,   3.09239522e-27,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.20974536e-10,   0.00000000e+00,   1.21074998e-13,\n",
       "          7.65907345e-04,   0.00000000e+00,   2.86606913e-14,\n",
       "          9.99234080e-01,   6.40097885e-35,   1.82639255e-12,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          5.17808417e-24,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  3.95197436e-16,   6.32136121e-08,   8.32314946e-12,\n",
       "          9.45641935e-01,   1.79000141e-03,   1.01926367e-12,\n",
       "          1.28718675e-10,   4.60149460e-02,   1.76935973e-05,\n",
       "          6.53521344e-03],\n",
       "       [  1.31686992e-20,   5.21182751e-32,   3.88761655e-05,\n",
       "          9.99961138e-01,   0.00000000e+00,   1.68000647e-16,\n",
       "          6.26313591e-24,   4.53764082e-10,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  5.10908625e-28,   0.00000000e+00,   4.55775711e-37,\n",
       "          2.10513562e-17,   0.00000000e+00,   1.00000000e+00,\n",
       "          5.92659144e-23,   2.98620484e-27,   5.14372710e-25,\n",
       "          1.19196562e-34],\n",
       "       [  0.00000000e+00,   8.59261882e-19,   8.98721311e-26,\n",
       "          0.00000000e+00,   3.69280503e-20,   2.65053271e-25,\n",
       "          1.00000000e+00,   9.91329406e-30,   6.83182890e-23,\n",
       "          0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   1.54838485e-33,\n",
       "          0.00000000e+00,   0.00000000e+00,   8.97483856e-20,\n",
       "          0.00000000e+00,   9.16433026e-26,   0.00000000e+00,\n",
       "          1.01813526e-34],\n",
       "       [  0.00000000e+00,   2.52196711e-34,   7.89430415e-33,\n",
       "          9.67372523e-29,   7.01322475e-34,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.28719816e-38,\n",
       "          4.02659426e-16],\n",
       "       [  2.50205025e-02,   2.74330884e-01,   7.24979109e-05,\n",
       "          1.04048167e-05,   6.26168167e-03,   6.03487669e-03,\n",
       "          5.08395553e-01,   1.38136536e-01,   6.79618006e-06,\n",
       "          4.17303145e-02],\n",
       "       [  3.98372967e-31,   0.00000000e+00,   4.53753602e-15,\n",
       "          1.54137736e-14,   3.48771322e-15,   3.96726101e-23,\n",
       "          0.00000000e+00,   9.99997735e-01,   4.91413640e-28,\n",
       "          2.20896641e-06],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.14526573e-37,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  8.05465581e-30,   1.65864384e-38,   5.18510521e-30,\n",
       "          0.00000000e+00,   7.80318202e-29,   0.00000000e+00,\n",
       "          0.00000000e+00,   5.50527241e-25,   7.50661171e-32,\n",
       "          1.00000000e+00],\n",
       "       [  5.64258147e-14,   6.06433503e-07,   8.02318880e-07,\n",
       "          6.08483573e-30,   9.99998331e-01,   5.25464139e-14,\n",
       "          2.54087126e-07,   3.15836980e-17,   9.89426399e-17,\n",
       "          2.77221708e-16],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.65012729e-34,   0.00000000e+00,   4.11760856e-21,\n",
       "          1.02093653e-32,   1.99036170e-30,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   6.84140571e-29,   3.09043522e-21,\n",
       "          4.12239991e-37,   3.18105229e-21,   5.04172254e-31,\n",
       "          1.00000000e+00,   0.00000000e+00,   8.88755902e-26,\n",
       "          0.00000000e+00],\n",
       "       [  1.18922361e-32,   3.32512263e-32,   3.28748636e-25,\n",
       "          1.86865742e-17,   4.21706770e-23,   2.37082924e-29,\n",
       "          9.50408487e-20,   7.02093430e-19,   1.00000000e+00,\n",
       "          1.96700318e-20],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   2.17305054e-35,\n",
       "          0.00000000e+00,   2.60221869e-36,   0.00000000e+00,\n",
       "          0.00000000e+00,   3.14723989e-31,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  2.51259168e-29,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.51993075e-32,   0.00000000e+00,   2.48824312e-12,\n",
       "          1.00000000e+00,   0.00000000e+00,   2.59119506e-35,\n",
       "          0.00000000e+00],\n",
       "       [  2.03806317e-21,   7.03752434e-31,   8.01046358e-19,\n",
       "          2.62127605e-06,   4.65522484e-18,   2.57663908e-28,\n",
       "          1.13261793e-23,   1.36799586e-10,   1.54010072e-15,\n",
       "          9.99997377e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  7.78282445e-21,   5.19146324e-14,   5.55783117e-07,\n",
       "          1.55497334e-11,   2.05877811e-01,   4.19374984e-13,\n",
       "          5.12114256e-15,   5.96085250e-01,   2.51363101e-12,\n",
       "          1.98036283e-01],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  3.04640280e-20,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.11727191e-29,   0.00000000e+00,   1.28045636e-20,\n",
       "          1.00000000e+00,   0.00000000e+00,   3.75943267e-38,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   7.31304790e-34,\n",
       "          1.00000000e+00,   0.00000000e+00,   4.64870455e-34,\n",
       "          0.00000000e+00,   3.13984643e-35,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   4.53339954e-20,   2.45435999e-21,\n",
       "          0.00000000e+00,   2.26002649e-37,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          4.00317283e-18],\n",
       "       [  5.68266861e-21,   1.64023337e-10,   9.41502108e-16,\n",
       "          3.47537162e-31,   9.88584518e-01,   1.25964790e-15,\n",
       "          1.14155030e-02,   1.24228461e-27,   1.10006896e-14,\n",
       "          5.06408706e-16],\n",
       "       [  5.40050060e-10,   0.00000000e+00,   3.44510273e-30,\n",
       "          1.28804926e-21,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   3.86162549e-25,   2.59631844e-14,\n",
       "          0.00000000e+00],\n",
       "       [  4.68548345e-32,   1.50616580e-30,   3.39289273e-28,\n",
       "          2.68069136e-30,   1.02230416e-22,   2.63058503e-32,\n",
       "          0.00000000e+00,   4.81173163e-03,   4.75951111e-22,\n",
       "          9.95188236e-01],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.99083302e-37,\n",
       "          0.00000000e+00,   3.69536781e-36,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.29660131e-19,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.00000000e+00,   3.32101868e-30,   0.00000000e+00,\n",
       "          1.52180122e-31,   6.23430565e-29,   2.38539845e-29,\n",
       "          8.48483761e-34,   3.99653340e-34,   1.45110215e-35,\n",
       "          9.52091473e-29],\n",
       "       [  2.60874602e-28,   1.84384873e-04,   1.74178235e-27,\n",
       "          5.98983739e-38,   9.99815643e-01,   4.04908378e-28,\n",
       "          1.38864110e-38,   2.99299648e-13,   2.53437532e-27,\n",
       "          2.35521814e-14],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.88317515e-19,\n",
       "          1.00000000e+00,   0.00000000e+00,   4.82423969e-32,\n",
       "          4.61423977e-17,   2.48140419e-38,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.79486883e-12,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   4.13908506e-38,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   4.12656190e-33,\n",
       "          0.00000000e+00,   1.47910324e-33,   5.15141025e-38,\n",
       "          3.98120463e-37,   8.36351253e-30,   1.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  4.12826760e-38,   3.87306663e-36,   1.32637732e-23,\n",
       "          1.74607412e-10,   1.14555372e-28,   6.70925682e-30,\n",
       "          7.80388461e-17,   2.06176335e-20,   1.00000000e+00,\n",
       "          2.44238404e-23],\n",
       "       [  0.00000000e+00,   2.58900757e-23,   2.58885410e-27,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          9.22876879e-20],\n",
       "       [  3.69678455e-04,   1.13954354e-06,   9.99291062e-01,\n",
       "          3.34114127e-04,   4.73936612e-10,   2.07931028e-09,\n",
       "          5.48052001e-13,   2.88323889e-08,   3.92617403e-06,\n",
       "          2.25517738e-08],\n",
       "       [  1.11789722e-09,   5.28547394e-16,   3.29478667e-10,\n",
       "          1.83167243e-13,   2.16143770e-10,   8.86187977e-15,\n",
       "          3.92390686e-16,   5.47575407e-09,   1.10617728e-15,\n",
       "          1.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.24803914e-21,\n",
       "          3.18178550e-33,   1.56355042e-25,   0.00000000e+00,\n",
       "          1.22719991e-37,   2.60644561e-10,   0.00000000e+00,\n",
       "          3.30655081e-34],\n",
       "       [  3.99918043e-10,   1.14463568e-04,   3.85413472e-07,\n",
       "          3.76273590e-09,   1.74121759e-10,   5.49473879e-17,\n",
       "          3.53757412e-10,   1.37796350e-13,   9.99885082e-01,\n",
       "          1.43603421e-10],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.39398070e-25,\n",
       "          0.00000000e+00,   1.92836143e-28,   0.00000000e+00,\n",
       "          0.00000000e+00,   3.19953845e-21,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  2.08540430e-37,   4.98999074e-36,   3.92627044e-32,\n",
       "          2.35484235e-34,   1.11859481e-20,   1.78718084e-29,\n",
       "          0.00000000e+00,   2.20219235e-19,   6.22876363e-30,\n",
       "          1.00000000e+00],\n",
       "       [  6.25557421e-23,   0.00000000e+00,   9.49909756e-32,\n",
       "          1.10543828e-24,   2.92154339e-32,   3.32503553e-31,\n",
       "          0.00000000e+00,   1.28071954e-21,   1.23481628e-30,\n",
       "          1.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.24880702e-34,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  6.61658123e-04,   1.82786211e-03,   1.10472072e-07,\n",
       "          1.87053650e-10,   8.67568202e-16,   3.79851706e-10,\n",
       "          5.76788621e-16,   9.42493972e-10,   1.73140842e-11,\n",
       "          9.97510314e-01],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   6.18183479e-34,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  7.49625641e-16,   0.00000000e+00,   2.20227855e-17,\n",
       "          1.00000000e+00,   0.00000000e+00,   7.04484515e-17,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.34923856e-03,   3.48661304e-01,   3.74786347e-01,\n",
       "          5.24346977e-02,   2.10125232e-03,   2.60219276e-02,\n",
       "          1.80625299e-04,   9.83054265e-02,   8.34877640e-02,\n",
       "          1.26714697e-02],\n",
       "       [  6.24054364e-09,   0.00000000e+00,   3.41115089e-32,\n",
       "          3.78807725e-17,   2.10966654e-35,   1.00000000e+00,\n",
       "          1.42120929e-17,   2.48642255e-26,   1.11199412e-16,\n",
       "          4.24285096e-09],\n",
       "       [  0.00000000e+00,   1.81437270e-18,   1.39769246e-32,\n",
       "          0.00000000e+00,   1.67006639e-37,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          3.61317680e-16],\n",
       "       [  8.79734886e-29,   1.74501995e-31,   4.01813235e-27,\n",
       "          1.00000000e+00,   1.65700290e-19,   1.34121490e-29,\n",
       "          5.27739615e-23,   1.74348654e-12,   1.10603805e-15,\n",
       "          1.27176203e-09],\n",
       "       [  3.27106923e-28,   0.00000000e+00,   8.05604143e-22,\n",
       "          9.99992490e-01,   2.41059407e-34,   0.00000000e+00,\n",
       "          7.51668404e-06,   1.13465293e-09,   1.00031347e-14,\n",
       "          1.69457823e-18],\n",
       "       [  2.02190523e-16,   0.00000000e+00,   1.23212275e-19,\n",
       "          2.89537926e-19,   6.35083319e-25,   1.64327445e-04,\n",
       "          4.00519889e-36,   6.58937206e-04,   9.99176562e-01,\n",
       "          8.94930565e-08],\n",
       "       [  2.64651560e-37,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.66888789e-30,   1.83938582e-31,   1.35786518e-34,\n",
       "          2.20704707e-32,   0.00000000e+00,   1.00000000e+00,\n",
       "          8.38478729e-30],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   2.75926905e-36,\n",
       "          1.18944921e-34,   3.29420253e-25,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.43952037e-12,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  4.30983490e-37,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   8.63998266e-34,   0.00000000e+00,\n",
       "          1.00000000e+00],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.61201615e-30,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   1.70860608e-17,\n",
       "          6.26611178e-29,   1.07863964e-19,   0.00000000e+00,\n",
       "          7.52037727e-30,   5.32998946e-19,   2.36937005e-32,\n",
       "          5.65465791e-29],\n",
       "       [  1.72098359e-14,   9.66854334e-01,   1.62021240e-06,\n",
       "          4.30138286e-10,   1.51359880e-09,   5.70539657e-11,\n",
       "          3.31438743e-02,   2.65216049e-09,   2.64708433e-07,\n",
       "          2.29221309e-09],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          8.58081370e-37],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.87047087e-30,\n",
       "          2.52602216e-14,   5.13521053e-28,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.90354379e-10,   1.00000000e+00,\n",
       "          4.66952341e-31],\n",
       "       [  1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.02361853e-34,   2.02475082e-33,\n",
       "          0.00000000e+00],\n",
       "       [  2.11236582e-26,   1.90099450e-20,   9.76294572e-24,\n",
       "          0.00000000e+00,   1.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   5.09793221e-20,   2.22459760e-22,\n",
       "          2.32359303e-34],\n",
       "       [  0.00000000e+00,   1.00000000e+00,   3.25070015e-24,\n",
       "          4.09557748e-31,   5.25259318e-15,   0.00000000e+00,\n",
       "          2.33304336e-34,   6.02937017e-22,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   1.00000000e+00,\n",
       "          4.41737943e-29,   0.00000000e+00,   3.41802842e-32,\n",
       "          1.30464158e-26,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   3.42284914e-21,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   4.29020254e-21,   1.91467146e-33,\n",
       "          0.00000000e+00],\n",
       "       [  2.79862154e-34,   0.00000000e+00,   1.70418438e-19,\n",
       "          1.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.02802814e-35,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  8.10113749e-13,   9.99977708e-01,   1.82444129e-10,\n",
       "          3.21311234e-07,   8.33770830e-09,   8.06945419e-15,\n",
       "          2.09702866e-05,   2.31924036e-09,   9.28130760e-07,\n",
       "          9.41235090e-10],\n",
       "       [  7.15258321e-12,   1.00000000e+00,   3.23671704e-17,\n",
       "          1.44059775e-09,   1.71570367e-08,   1.07638356e-18,\n",
       "          1.36040986e-13,   8.18998751e-16,   8.91110241e-11,\n",
       "          3.25213717e-10],\n",
       "       [  9.67542019e-06,   2.30628120e-06,   9.92455840e-01,\n",
       "          2.02129222e-03,   5.05764224e-03,   3.03312504e-08,\n",
       "          1.76139496e-04,   1.81212265e-04,   7.69900143e-05,\n",
       "          1.87872447e-05],\n",
       "       [  1.41377779e-27,   0.00000000e+00,   1.00000000e+00,\n",
       "          1.23110228e-20,   2.46605173e-30,   2.13109043e-15,\n",
       "          1.93097704e-18,   9.58616634e-18,   1.41559937e-08,\n",
       "          0.00000000e+00],\n",
       "       [  3.01732161e-17,   9.98883426e-01,   8.08673207e-17,\n",
       "          2.59561795e-13,   1.46354159e-05,   1.25117700e-20,\n",
       "          1.10177742e-03,   1.18859715e-19,   1.47175740e-07,\n",
       "          1.04428152e-20],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          6.78812036e-27,   0.00000000e+00,   4.00730331e-38,\n",
       "          0.00000000e+00,   1.13851713e-22,   1.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  3.09488293e-21,   3.83024237e-11,   6.58771868e-17,\n",
       "          0.00000000e+00,   1.00000000e+00,   1.11832045e-11,\n",
       "          3.04257192e-19,   5.10568855e-16,   3.60277888e-12,\n",
       "          1.38181816e-12],\n",
       "       [  2.92361401e-34,   0.00000000e+00,   4.96412073e-33,\n",
       "          2.18249504e-21,   5.61373707e-36,   2.08369354e-38,\n",
       "          9.06699751e-34,   3.80506056e-27,   1.00000000e+00,\n",
       "          3.03942206e-23],\n",
       "       [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.00000000e+00,   0.00000000e+00,   3.77889205e-35,\n",
       "          0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
