{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "sys.path.append('../..')\n",
    "sys.path.append('../classification/')\n",
    "\n",
    "from dataset.dataset.image import ImagesBatch\n",
    "from dataset import Dataset, DatasetIndex, B, V\n",
    "from detection_mnist import DetectionMnist\n",
    "from faster_rcnn import FRCNNModel\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_SHAPE = (64, 64)\n",
    "MAP_SHAPE = (8, 8)\n",
    "N_ANCHORS = MAP_SHAPE[0] * MAP_SHAPE[1] * 9\n",
    "MNIST_PER_IMAGE = 5\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = DatasetIndex(np.arange(20000))          \n",
    "mnist = Dataset(ind, batch_class=DetectionMnist)   \n",
    "mnist.cv_split([0.9, 0.1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.path.append('../task_03')\n",
    "\n",
    "from dataset.dataset.models.tf.layers import conv_block\n",
    "from dataset.dataset.models.tf import TFModel\n",
    "from vgg import VGGModel\n",
    "\n",
    "class FRCNNModel(TFModel):\n",
    "    \"\"\"LinkNet as TFModel\"\"\"\n",
    "    def _build(self, *args, **kwargs):\n",
    "\n",
    "        #n_classes = self.num_channels('masks')\n",
    "        _, inp2 = self._make_inputs(['images'])\n",
    "        data_format = self.data_format('images')\n",
    "        dim = self.spatial_dim('images')\n",
    "        b_norm = self.get_from_config('batch_norm', True)\n",
    "\n",
    "        conv = {'data_format': data_format}\n",
    "        batch_norm = {'momentum': 0.1}\n",
    "\n",
    "        kwargs = {'conv': conv, 'batch_norm': batch_norm}\n",
    "        \n",
    "        inp = inp2['images']\n",
    "        with tf.variable_scope('FRCNN'): # pylint: disable=not-context-manager\n",
    "            net = VGGModel.fully_conv_block(dim, inp, b_norm, 'VGG7', **kwargs)\n",
    "            net = conv_block(dim, net, 512, 3, 'ca', **kwargs)\n",
    "            reg = conv_block(dim, net, 4*9, 1, 'ca', **kwargs)\n",
    "            cls = conv_block(dim, net, 1*9, 1, 'c', **kwargs)\n",
    "\n",
    "        reg = tf.reshape(reg, [-1, N_ANCHORS, 4], name='RoI')\n",
    "        cls = tf.reshape(cls, [-1, N_ANCHORS], name='IoU')\n",
    "        true_cls = tf.placeholder(tf.float32, shape = [None, N_ANCHORS], name='proposal_targets')\n",
    "        true_reg = tf.placeholder(tf.float32, shape = [None, N_ANCHORS, 4], name='bbox_targets')\n",
    "        \n",
    "        loss = self.rpn_loss(reg, cls, true_reg, true_cls)\n",
    "        loss = tf.identity(loss, name='loss')\n",
    "        tf.losses.add_loss(loss)\n",
    "    \n",
    "    def rpn_loss(self, reg, cls, true_reg, true_cls):\n",
    "        cls_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=true_cls, logits=cls) / MNIST_PER_IMAGE   \n",
    "        cls_loss = tf.reduce_sum(cls_loss, axis=-1)\n",
    "        cls_loss = tf.reduce_mean(cls_loss, name='cls_loss')\n",
    "\n",
    "        sums = tf.reduce_sum((true_reg - reg) ** 2, axis=-1)\n",
    "        reg_mask = tf.cast(true_cls, dtype=tf.float32)\n",
    "        reg_mask = tf.reshape(reg_mask, shape=[-1, N_ANCHORS])\n",
    "\n",
    "        reg_loss = sums * true_cls\n",
    "        reg_loss = tf.reduce_sum(reg_loss, axis=-1)\n",
    "        reg_loss = tf.reduce_mean(reg_loss, name='reg_loss')\n",
    "        \n",
    "        loss = reg_loss * 10 + cls_loss\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "placeholders_config = {\n",
    "                       'images': {'shape': IMAGE_SHAPE + (1,),\n",
    "                                 'dtype': 'float32',\n",
    "                                 'data_format': 'channels_last',\n",
    "                                 'name': 'reshaped_images'},\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_config = {'inputs': placeholders_config,\n",
    "                'batch_norm': True,\n",
    "                'optimizer': 'Adam'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feed_dict = {'images': B('images'),\n",
    "                   'proposal_targets': B('clsf'),\n",
    "                   'bbox_targets': B('reg')}        \n",
    "\n",
    "test_feed_dict = {'images': B('images'),\n",
    "                   'proposal_targets': B('clsf'),\n",
    "                   'bbox_targets': B('reg')}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pp = (mnist.train.p\n",
    "            .init_model('static', FRCNNModel, 'frcnn', config=model_config)\n",
    "            .init_variable('loss_history', init_on_each_run=list)\n",
    "            .init_variable('IoU_predictions', init_on_each_run=list)\n",
    "            .load_images()\n",
    "            .generate_multimnist_images(image_shape=IMAGE_SHAPE, max_dig=MNIST_PER_IMAGE)\n",
    "            .create_anchors(IMAGE_SHAPE, MAP_SHAPE)\n",
    "            .create_reg_cls()\n",
    "            .param_reg()\n",
    "            .train_model('frcnn', \n",
    "                         fetches=['loss', 'reg_loss', 'cls_loss'],\n",
    "                         feed_dict=train_feed_dict,\n",
    "                         save_to=V('loss_history'), \n",
    "                         mode='a'\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 10: [16.120089, 1.0291331, 5.8287587]\n",
      "Iter 20: [14.707017, 1.0664941, 4.0420761]\n",
      "Iter 30: [13.128283, 1.0180069, 2.9482136]\n",
      "Iter 40: [12.571494, 0.98477441, 2.7237501]\n",
      "Iter 50: [13.363638, 1.0740654, 2.6229837]\n",
      "Iter 60: [10.742109, 0.85752404, 2.1668689]\n",
      "Iter 70: [11.860249, 0.95682609, 2.2919879]\n",
      "Iter 80: [12.33462, 0.99792016, 2.3554187]\n",
      "Iter 90: [13.056274, 1.0633078, 2.423197]\n",
      "Iter 100: [13.954223, 1.1554145, 2.4000778]\n",
      "Iter 110: [11.507006, 0.94614482, 2.0455565]\n",
      "Iter 120: [11.549006, 0.94783378, 2.0706675]\n",
      "Iter 130: [11.108252, 0.93359059, 1.7723455]\n",
      "Iter 140: [11.489969, 0.96212578, 1.8687111]\n",
      "Iter 150: [11.947775, 0.99760282, 1.9717464]\n",
      "Iter 160: [10.60153, 0.87902176, 1.8113127]\n",
      "Iter 170: [12.191529, 1.0286627, 1.9049022]\n",
      "Iter 180: [11.639009, 0.97798145, 1.8591949]\n",
      "Iter 190: [11.639383, 0.98386306, 1.8007524]\n",
      "Iter 200: [11.43763, 0.95782238, 1.8594055]\n",
      "Iter 210: [11.11263, 0.93504912, 1.7621385]\n",
      "Iter 220: [11.1482, 0.94081646, 1.7400347]\n",
      "Iter 230: [12.695911, 1.0784878, 1.9110336]\n",
      "Iter 240: [11.466985, 0.97175962, 1.7493885]\n",
      "Iter 250: [12.167559, 1.0509943, 1.6576157]\n",
      "Iter 260: [11.173302, 0.96405023, 1.5327997]\n",
      "Iter 270: [10.441148, 0.87183106, 1.7228377]\n",
      "Iter 280: [12.082404, 1.0324249, 1.7581551]\n",
      "Iter 290: [11.416089, 0.96662021, 1.7498863]\n",
      "Iter 300: [11.822196, 1.0226154, 1.5960414]\n",
      "Iter 310: [12.030365, 1.0492094, 1.5382707]\n",
      "Iter 320: [11.314459, 0.98065555, 1.5079029]\n",
      "Iter 330: [11.283371, 0.98171568, 1.4662147]\n",
      "Iter 340: [10.85541, 0.92765206, 1.5788894]\n",
      "Iter 350: [11.839693, 1.0242442, 1.5972512]\n",
      "Iter 360: [11.34479, 0.96599382, 1.6848516]\n",
      "Iter 370: [12.146985, 1.0622506, 1.5244792]\n",
      "Iter 380: [11.545565, 1.0145249, 1.400315]\n",
      "Iter 390: [10.611826, 0.92507404, 1.3610859]\n",
      "Iter 400: [10.636174, 0.92614591, 1.3747149]\n",
      "Iter 410: [10.929969, 0.94208866, 1.5090818]\n"
     ]
    }
   ],
   "source": [
    "for i in range(500):\n",
    "    batch = train_pp.next_batch(BATCH_SIZE, n_epochs=None, shuffle=True)\n",
    "    if (i+1) % 10 == 0:\n",
    "        #print(batch.data.bbox_batch_sizes)\n",
    "        print('Iter {}: {}'.format(i+1, train_pp.get_variable('loss_history')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_loss = np.array(train_pp.get_variable('loss_history'))[:,1]\n",
    "cls_loss = np.array(train_pp.get_variable('loss_history'))[:,2]\n",
    "total_loss = np.array(train_pp.get_variable('loss_history'))[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.log(total_loss), label='Total loss')\n",
    "plt.plot(np.log(reg_loss), label='Reg loss')\n",
    "plt.plot(np.log(cls_loss), label='Cls loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pp = (mnist.test.p\n",
    "            .import_model('frcnn', train_pp)\n",
    "            .load_images()\n",
    "            .generate_multimnist_images(image_shape=IMAGE_SHAPE, max_dig=MNIST_PER_IMAGE)\n",
    "            .create_anchors(IMAGE_SHAPE, MAP_SHAPE)\n",
    "            .create_reg_cls()\n",
    "            .param_reg()\n",
    "            .predict_model('frcnn', \n",
    "                           fetches=['RoI','IoU'],\n",
    "                           feed_dict=test_feed_dict,\n",
    "                           save_to=[B('RoI_predictions'), B('IoU_predictions')])\n",
    "            .unparam_predictions())\n",
    "\n",
    "batch = test_pp.next_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "im = batch.data.images[i]\n",
    "bboxes = batch.data.bboxes[i]\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "ax.imshow(im)\n",
    "\n",
    "for bbox in bboxes:    \n",
    "    rect = patches.Rectangle((bbox[1], bbox[0]), bbox[2], bbox[3] ,linewidth=1,edgecolor='g',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    im = batch.data.images[i]\n",
    "    bboxes = batch.data.RoI_predictions[i]\n",
    "    selected_RoI = batch.data.IoU_predictions[i]\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "\n",
    "    ax.imshow(im)\n",
    "\n",
    "    for bbox in bboxes[selected_RoI > 0.5]:    \n",
    "        rect = patches.Rectangle((bbox[1], bbox[0]), bbox[2], bbox[3], linewidth=1, edgecolor='r',facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
