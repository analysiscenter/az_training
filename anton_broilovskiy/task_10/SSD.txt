SSD11.025% 

Сегодня мы с вами рассмотрим задачу нахождения объектов на изображении. Мы уже знаем одну арихтектуру, которая может это делать - Yolo, а теперь мы поговорим о немного другой архитектуре, которая находит объекты и лучше, и иногда быстрее, чем Yolo. Назвается она sigle short detector or SSD. Сейчас мы приступим к рассмотрению архитектуры, а затем для создания полной картины, поговорим положительных и отрицательных сторонах модели.

SSD это одна из двух моделей, которые решают задачу детекции в один этап. Первый раз этот метод был применен в Yolo, о которой мы говорили ранее, она и легла в основу SSD. Если в Yolo выходом нейросети является набор векоторов на основе которых происходит выбор бб. То в SSD такая операция происходит несколько раз на протяжении всей сети. Давайте по-подробней поговорим об архитектуре.

Своим устройством SSD так же напоминает Yolo, изачально мы так же берем предобученную модель и тоже дополняем её конволюционными слоями с нелинейностями. Первое отличие бросающиеся в глаза это то, что в SSD нет полносвязных слоев, вместо этого конволюционные слои сворачивают изображение до размера 1х1. В Yolo предсказание бб происходит 1 раз для выходного набора карт. В SSD же мы для предсказания бб учитываем разноразмерные карты, которые берем после каждого дополнительного сверточного слоя, и из середины обученной сети. Карты с различных слоев имеет смысл рассмативать, для того чтобы лучше детектировать объекты различного размера.
Затем для каждого набора карт происходит предсказание бб или их отсутствия. В конце все предсказанные бб проходят через non-maximum suppression алгоритм на выходе которого остаются предсказанные бб.
Давайте подробнее рассмотрим что как именно модель использует карты для предсказания бб.
Так как каждая клетка на feature map имеет определенный receptive field на исходном изображении, мы будем проецировать туда default box'ы, сами выбирая размеры каждого db и их количество, походим образом это делалось в Yolo.
Для которых мы далее будем предсказывать смещение и принадлежность к одному из классов.

Изначально набор фильтров проходит через 2 парралельных конволюционных слоя с ядрами 3х3. После прохождения первого конволюционного получается набор фильтров такого-же размера, но с другим количеством фильтов. В каждой ячейке полученного набора будет вектор длины ((количество классов + фон) * число различных бб) и значением каждой клетки будет скор по определенному классу.
Другая конволюция так же изменяет только количество фильтров. Но только в этом случае, в каждой ячеке будет вектор со значениями смещения для каждого из db, то есть его длина будет (4(коррекция по x,y и h,w) * количество бб).
Далее скоры, полученные после первой конволюции прогоняются через softmax для получения вероятностей. Для уменьшения количества ложных срабатываний, все предсказания проходят фильтрацию по confidence (зануляются маленькие вероятности).
Такая операция повторяется для всех наборов карт. Тут надо обратить внимание, что исходные размеры default box'ов для всех карт одинаковые.

После того, как мы сделали предсказания для всех наборов карт, предсказания они через алгоритим non-maximum suppression. Этот алгоритм заключается в сравнении пересечений предсказанных бб. 



""
* Об архитектуре
* Про то, что сначала идет обученная модель из середины которой мы начинаем выбирать карты
* Достаиваем модель
* Про сопоставление вектору фильтров, бб на самом изображении. Что каждый фильтр в этом наборе имеет свой смысл.
* Про появление бб, разделение на предсказание ширины, высоты и класса для каждого бб
* Non-maximum suppression.
* По-моему стоит вставить конкретики которой не хватает при построении архитектуры. Парни говорили, что им не хватило инфы в видео и в статье как именно это делать, может про это стоит сказать.
* Плюсы / минусы.