{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook contains a demonstration of regression models using tensorflow and dataset\n",
    "The models are implemented as methods of the class MyBatch in linear.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import seaborn\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from dataset import Dataset\n",
    "import linear as lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=[]\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://66.147.244.197/~globerov/introspectivemode/wp-content/uploads/2012/08/regression-265x300.jpeg)\n",
    "\n",
    "Let's consiider a linear regression problem where $y \\in \\mathbb{R}$ and the relationship can be modeled as\n",
    "$$y(x) = \\langle w, x\\rangle$$ where $x \\in \\mathbb{R}^{d+1}$ - vector consisting of d independent variables concatenated to a vector of ones. To find the solution  $w \\in \\mathbb{R} ^{d+1}$ we minimize the average sum of squared residuals. In case of $l_2$ regularization the minimized functional looks like:\n",
    "\n",
    "$$ \\frac{1}{N}\\sum_{i=1}^N (\\langle w, x_i \\rangle - y_i) ^ 2 + \\dfrac{C}{2}\\lVert w \\rVert^2  \\to \\min_w$$\n",
    "We find the solution using stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "TRAINING_EPOCHS = 500\n",
    "DATA_SIZE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr.load_linear_data returns np.array of feautures and linearly dependent target with error from normal distribution\n",
    "data = lr.load_linear_data(DATA_SIZE)\n",
    "\n",
    "# create dataset object\n",
    "my_dataset = Dataset(index=np.arange(data[0].shape[0]), batch_class=lr.MyBatch)\n",
    "\n",
    "# create train and test indices\n",
    "my_dataset.cv_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "cost_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.dataset.pipeline.Pipeline at 0x1a7002bb518>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and run train pipeline which loads, preprocesses and trains linear regression model\n",
    "my_dataset.train.pipeline() \\\n",
    "    .load(data) \\\n",
    "    .preprocess_linear_data() \\\n",
    "    .train_linear(sess, cost_history) \\\n",
    "    .run(BATCH_SIZE, shuffle=True, n_epochs=TRAINING_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create empty lists to store labels, features, predictions and error\n",
    "y_true, y_pred, mse, x_features = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and run test pipeline which loads, preprocesses and tests the trained model\n",
    "test_batch = my_dataset.test.pipeline() \\\n",
    "    .load(data) \\\n",
    "    .preprocess_linear_data() \\\n",
    "    .test_linear(sess, y_true, y_pred, mse, x_features) \\\n",
    "    .run(len(my_dataset.test.indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance ratio: 0.78\n"
     ]
    }
   ],
   "source": [
    "variance = np.var(y_pred, ddof=1) / np.var(y_true, ddof=1)\n",
    "print('Variance ratio: %.2f' % variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is distibuted in the interval: 0.11 $ ± 0.28 $\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(np.abs(np.array(y_pred) - np.array(y_true)))\n",
    "interval = 3*np.std(np.abs(np.array(y_pred) - np.array(y_true)))\n",
    "print('MSE is distibuted in the interval: {0:.2f} $ ± {1:.2f} $'\\\n",
    "        .format(mean, interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE with respect to data's mean is: 2.92%\n"
     ]
    }
   ],
   "source": [
    "absolute_error_ratio = np.mean(np.abs(np.array(y_pred) - np.array(y_true))/np.array(y_true))*100\n",
    "print('MAE with respect to data\\'s mean is: {0:.2f}%'\\\n",
    "        .format(absolute_error_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is used for binary classification problem. In case of $y \\in \\{-1, 1\\}$ the model looks like $y = sign \\langle w, x\\rangle$ and the minimized functional is:\n",
    "$$ \\dfrac{1}{N}\\sum_{i=1}^N \\log(1 + \\exp(-\\langle w, x_i \\rangle y_i)) + \\dfrac{C}{2}\\lVert w \\rVert^2  \\to \\min_w$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create random data for classification\n",
    "data = lr.load_random_data(blobs=False)\n",
    "\n",
    "# create dataset object\n",
    "my_dataset = Dataset(index=np.arange(data[0].shape[0]), batch_class=lr.MyBatch)\n",
    "\n",
    "# create train and test indices\n",
    "my_dataset.cv_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "cost_history = []\n",
    "acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.dataset.pipeline.Pipeline at 0x1a7002bb828>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and run train pipeline which loads, preprocesses and trains logistic regression model\n",
    "my_dataset.train.pipeline() \\\n",
    "    .load(data) \\\n",
    "    .preprocess_binary_data() \\\n",
    "    .train_logistic(sess, cost_history, acc_history) \\\n",
    "    .run(BATCH_SIZE, shuffle=True, n_epochs=TRAINING_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create and run test pipeline which loads, preprocesses and tests the trained model\n",
    "test_batch = my_dataset.test.pipeline() \\\n",
    "    .load(data) \\\n",
    "    .preprocess_binary_data() \\\n",
    "    .test_logistic(sess, accuracy) \\\n",
    "    .run(len(my_dataset.test.indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY: 95%\n"
     ]
    }
   ],
   "source": [
    "print(\"ACCURACY: %.0f%%\" % (100.0 * accuracy[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson regression is used to model count data. It assumes the target variable Y has a Poisson distribution. The model takes the form: $$\\log \\operatorname {E} (\\mathrm{Y}\\mid x )=\\langle w, x \\rangle \\,$$ \n",
    "and the minimized functional looks like:\n",
    "$$ \\sum_{i=1}^N y_i \\langle w, x_i \\rangle - \\exp{\\langle w, x_i \\rangle} + \\dfrac{C}{2}\\lVert w \\rVert^2 \\to \\min_w$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lr.load_poisson_data generates sample from poisson distribution and returns a tuple of weights, features and labels\n",
    "data = lr.load_poisson_data()\n",
    "\n",
    "# create dataset object\n",
    "my_dataset = Dataset(index=np.arange(data[1].shape[0]), batch_class=lr.MyBatch)\n",
    "\n",
    "# create train and test indices\n",
    "my_dataset.cv_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "cost_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<dataset.dataset.pipeline.Pipeline at 0x1a700371470>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create and run train pipeline which loads, preprocesses and trains poisson regression model\n",
    "my_dataset.train.pipeline() \\\n",
    "    .load(data[1:]) \\\n",
    "    .train_poisson(sess, cost_history) \\\n",
    "    .run(BATCH_SIZE, shuffle=True, n_epochs=TRAINING_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit, y_true, weights = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_batch = my_dataset.test.pipeline() \\\n",
    "    .load(data[1:]) \\\n",
    "    .test_poisson(sess, y_true, logit, weights) \\\n",
    "    .run(len(my_dataset.test.indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance ratio: 0.86\n"
     ]
    }
   ],
   "source": [
    "variance_ratio = np.var(logit, ddof=1) / np.var(np.dot(data[1], data[0]), ddof=1)\n",
    "print('Variance ratio: %.2f' % (variance_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE of the model with respect to data's mean is: 15.54%\n"
     ]
    }
   ],
   "source": [
    "abs_error_ratio = np.mean(np.abs(np.exp(logit) - y_true))/np.mean(y_true)*100 \n",
    "print('MAE of the model with respect to data\\'s mean is: {0:.2f}%'\\\n",
    "        .format(abs_error_ratio))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
