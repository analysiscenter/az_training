{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microbatch training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производится обучение модели с помощью градиентного спуска или его модификаций, при котором градиенты считаются по батчам (например, размера 1024). Для оптимизации работы с памятью GPU предлагается разбивать батчи на микробатчи (например, размера 16), оценивать градиенты для каждого микробатча по отдельности, затем на их основе считать градиент уже для всего батча и делать шаг оптимизации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(os.path.join('..','..'))\n",
    "\n",
    "from az_training.task_01.microbatch import load, define_model, train_on_batch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предлагаемый алгоритм рассмотрим на примере MNIST размера $28 \\times 28$. Посмотрим, как будет меняться время выполнения одного шага обучения на батче в зависимости от размера микробатча. Разбиение на микробатчи производится на уровне numpy (см. microbatch.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST_SIZE = 2048\n",
    "N_EPOCHS = 2\n",
    "BATCH_SIZE = 1024\n",
    "N_ITER = MNIST_SIZE // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных\n",
    "images, labels = load(MNIST_SIZE)\n",
    "\n",
    "# определим tf модель (3 свёрточных слоя, 2 полносвязных)\n",
    "session, x_ph, y_ph, set_zero, accum_op, train_op, loss = define_model()\n",
    "\n",
    "# рассмотрим микробатчи размера, кратного BATCH_SIZE (1,2,4,...)\n",
    "grid = np.arange(1,BATCH_SIZE+1)[(BATCH_SIZE % np.arange(1,BATCH_SIZE+1)) == 0][-5:]\n",
    "times_per_iter = []\n",
    "\n",
    "print(grid)\n",
    "\n",
    "for micro_batch_size in grid:\n",
    "    times = []\n",
    "    rams = []\n",
    "    ix = np.arange(len(images))\n",
    "    for ep in tqdm(range(N_EPOCHS)):\n",
    "        np.random.shuffle(ix)\n",
    "        for it in range(N_ITER):\n",
    "            indices = ix[it * BATCH_SIZE: (it + 1) * BATCH_SIZE]\n",
    "            batch_x = images[indices]\n",
    "            batch_y = labels[indices]\n",
    "            time_it= train_on_batch(session, \n",
    "                                    [x_ph, y_ph], \n",
    "                                    [batch_x, batch_y], \n",
    "                                    micro_batch_size, \n",
    "                                    set_zero, \n",
    "                                    accum_op, \n",
    "                                    train_op)\n",
    "            times.append(time_it)\n",
    "    times_per_iter.append(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обучение по микробатчам\n",
    "\"\"\"\n",
    "    session.run(set_zero)\n",
    "    for x, y in zip(x_splitted, y_splitted):\n",
    "        session.run(accum_op, feed_dict={x_ph: x, y_ph: y})\n",
    "    session.run(train_op)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_per_iter = np.mean(np.array(times_per_iter), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(time_per_iter)\n",
    "plt.xticks(range(len(grid)), grid)\n",
    "plt.xlabel('Microbatch size')\n",
    "plt.ylabel('Time per iteration, s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой подход к реализации алгоритма основан на разбиении батча на микробатчи с помощью tf.split на уровне tensorflow (см. subbatch.py). Оказалось, что при малом разбиении на микробатчи сильно расходуется память, что скорее всего связано с реализацией split в tensorflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
